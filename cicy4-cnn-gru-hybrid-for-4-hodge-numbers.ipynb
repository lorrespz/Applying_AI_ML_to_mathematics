{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e39c470b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-25T10:49:53.412787Z",
     "iopub.status.busy": "2024-03-25T10:49:53.412420Z",
     "iopub.status.idle": "2024-03-25T10:49:59.118175Z",
     "shell.execute_reply": "2024-03-25T10:49:59.117382Z"
    },
    "papermill": {
     "duration": 5.71707,
     "end_time": "2024-03-25T10:49:59.120403",
     "exception": false,
     "start_time": "2024-03-25T10:49:53.403333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8cffccb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:49:59.136731Z",
     "iopub.status.busy": "2024-03-25T10:49:59.135962Z",
     "iopub.status.idle": "2024-03-25T10:50:12.399208Z",
     "shell.execute_reply": "2024-03-25T10:50:12.398235Z"
    },
    "papermill": {
     "duration": 13.273606,
     "end_time": "2024-03-25T10:50:12.401382",
     "exception": false,
     "start_time": "2024-03-25T10:49:59.127776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((921497, 16, 20), (921497, 4), (921497,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "path = '/kaggle/input/calabi-yau-cicy-4-folds/'\n",
    "\n",
    "conf = np.load('/kaggle/input/calabi-yau-cicy-4-folds/conf.npy')\n",
    "hodge = np.load(os.path.join(path, 'hodge.npy'))\n",
    "direct = np.load(os.path.join(path, 'direct.npy'))\n",
    "conf.shape, hodge.shape, direct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78382288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:12.417055Z",
     "iopub.status.busy": "2024-03-25T10:50:12.416731Z",
     "iopub.status.idle": "2024-03-25T10:50:12.421202Z",
     "shell.execute_reply": "2024-03-25T10:50:12.420337Z"
    },
    "papermill": {
     "duration": 0.014662,
     "end_time": "2024-03-25T10:50:12.423182",
     "exception": false,
     "start_time": "2024-03-25T10:50:12.408520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('saved_models'):\n",
    "    os.makedirs('saved_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0796b45d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:12.438177Z",
     "iopub.status.busy": "2024-03-25T10:50:12.437890Z",
     "iopub.status.idle": "2024-03-25T10:50:12.548675Z",
     "shell.execute_reply": "2024-03-25T10:50:12.547915Z"
    },
    "papermill": {
     "duration": 0.120923,
     "end_time": "2024-03-25T10:50:12.551067",
     "exception": false,
     "start_time": "2024-03-25T10:50:12.430144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/calabi-yau-cicy-4-folds')\n",
    "from CICY4_functions import data_generator, batch_gd_scheduler,  calc_accuracy_mr, plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12e41825",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:12.567167Z",
     "iopub.status.busy": "2024-03-25T10:50:12.566852Z",
     "iopub.status.idle": "2024-03-25T10:50:12.794348Z",
     "shell.execute_reply": "2024-03-25T10:50:12.793507Z"
    },
    "papermill": {
     "duration": 0.2382,
     "end_time": "2024-03-25T10:50:12.796677",
     "exception": false,
     "start_time": "2024-03-25T10:50:12.558477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test(X, y):\n",
    "    X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 101, shuffle = True)\n",
    "    \n",
    "    X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "    #only need reshape if the y dimension is 1\n",
    "    #y_train = torch.from_numpy(y_train.astype(np.float32).reshape(-1, 1))\n",
    "    y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "\n",
    "    X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "    #y_test = torch.from_numpy(y_test.astype(np.float32).reshape(-1, 1))\n",
    "    y_test = torch.from_numpy(y_test.astype(np.float32))                         \n",
    "    \n",
    "    print(f'X_train shape: {X_train.shape}, \\n y_train shape:{y_train.shape},\\\n",
    "                 \\n X_test shape: {X_test.shape}, \\n y_test shape:{y_test.shape}')\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a1fa4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:12.812841Z",
     "iopub.status.busy": "2024-03-25T10:50:12.812273Z",
     "iopub.status.idle": "2024-03-25T10:50:14.141381Z",
     "shell.execute_reply": "2024-03-25T10:50:14.140069Z"
    },
    "papermill": {
     "duration": 1.339302,
     "end_time": "2024-03-25T10:50:14.143494",
     "exception": false,
     "start_time": "2024-03-25T10:50:12.804192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([737197, 16, 20]), \n",
      " y_train shape:torch.Size([737197, 4]),                 \n",
      " X_test shape: torch.Size([184300, 16, 20]), \n",
      " y_test shape:torch.Size([184300, 4])\n"
     ]
    }
   ],
   "source": [
    "X = conf\n",
    "y = hodge\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test(X, y)\n",
    "\n",
    "train_gen = lambda: data_generator(X_train, y_train)\n",
    "test_gen = lambda: data_generator(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce86b72f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:14.158840Z",
     "iopub.status.busy": "2024-03-25T10:50:14.158509Z",
     "iopub.status.idle": "2024-03-25T10:50:14.215020Z",
     "shell.execute_reply": "2024-03-25T10:50:14.214175Z"
    },
    "papermill": {
     "duration": 0.066688,
     "end_time": "2024-03-25T10:50:14.217290",
     "exception": false,
     "start_time": "2024-03-25T10:50:14.150602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b062ad4d",
   "metadata": {
    "papermill": {
     "duration": 0.006723,
     "end_time": "2024-03-25T10:50:14.232156",
     "exception": false,
     "start_time": "2024-03-25T10:50:14.225433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CNN-RNN hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d24895b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:14.247496Z",
     "iopub.status.busy": "2024-03-25T10:50:14.246976Z",
     "iopub.status.idle": "2024-03-25T10:50:14.254041Z",
     "shell.execute_reply": "2024-03-25T10:50:14.253217Z"
    },
    "papermill": {
     "duration": 0.016893,
     "end_time": "2024-03-25T10:50:14.255905",
     "exception": false,
     "start_time": "2024-03-25T10:50:14.239012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################### CNN ###############################\n",
    "class CNN_block(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,128, 4, 1)\n",
    "        #self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.conv2 = nn.Conv2d(128,64, 3, 1)\n",
    "        #self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.mxpool = nn.MaxPool2d(2,2)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.conv_total = nn.Sequential(\n",
    "            self.conv1,\n",
    "            #self.bn1,\n",
    "            self.mxpool,\n",
    "            #self.bn2,\n",
    "            self.conv2,\n",
    "            self.mxpool,\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv_total(x))\n",
    "        #reshape is the same as flat(x)\n",
    "        #x = x.reshape(x.shape[0], -1)\n",
    "        x = self.flat(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4710af2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:14.270956Z",
     "iopub.status.busy": "2024-03-25T10:50:14.270685Z",
     "iopub.status.idle": "2024-03-25T10:50:14.454653Z",
     "shell.execute_reply": "2024-03-25T10:50:14.453700Z"
    },
    "papermill": {
     "duration": 0.193735,
     "end_time": "2024-03-25T10:50:14.456658",
     "exception": false,
     "start_time": "2024-03-25T10:50:14.262923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_block(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (mxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (conv_total): Sequential(\n",
       "    (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_block = CNN_block()\n",
    "cnn_block.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e463279a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:14.472561Z",
     "iopub.status.busy": "2024-03-25T10:50:14.472275Z",
     "iopub.status.idle": "2024-03-25T10:50:14.479700Z",
     "shell.execute_reply": "2024-03-25T10:50:14.478857Z"
    },
    "papermill": {
     "duration": 0.017475,
     "end_time": "2024-03-25T10:50:14.481578",
     "exception": false,
     "start_time": "2024-03-25T10:50:14.464103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNN_block(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden, n_rnnlayers, n_outputs):\n",
    "        super(RNN_block,self).__init__()\n",
    "        self.D = n_inputs\n",
    "        self.M = n_hidden\n",
    "        self.K = n_outputs\n",
    "        self.L = n_rnnlayers        \n",
    "        #self.lstm = nn.LSTM(input_size = self.D,\n",
    "        #                   hidden_size = self.M,\n",
    "        #                   num_layers = self.L,\n",
    "        #                   batch_first = True)    \n",
    "        self.gru = nn.GRU(input_size = self.D,\n",
    "                           hidden_size = self.M,\n",
    "                           num_layers = self.L,\n",
    "                           batch_first = True)\n",
    "        #self.fc1 = nn.Linear(self.M, 128)\n",
    "        #self.fc2 = nn.Linear(128, self.K)\n",
    "    def forward(self, X):\n",
    "        #input X is NxTxD\n",
    "        #initial hidden states\n",
    "        h0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
    "        #c0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
    "        #get LSTM unit output:\n",
    "        #output is NxTxM\n",
    "        #out, _ = self.lstm(X, (h0,c0))\n",
    "        out, _ = self.gru(X, h0)   \n",
    "        #we only want h(T) at the final time step\n",
    "        # output is now of shape (N, M)\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ed21177",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:14.497426Z",
     "iopub.status.busy": "2024-03-25T10:50:14.496837Z",
     "iopub.status.idle": "2024-03-25T10:50:14.631293Z",
     "shell.execute_reply": "2024-03-25T10:50:14.630380Z"
    },
    "papermill": {
     "duration": 0.144628,
     "end_time": "2024-03-25T10:50:14.633441",
     "exception": false,
     "start_time": "2024-03-25T10:50:14.488813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_block(\n",
       "  (gru): GRU(20, 100, num_layers=8, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gru_block = RNN_block(20, 64, 6, 4)\n",
    "gru_block = RNN_block(20, 100, 8, 4)\n",
    "gru_block.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fde74b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:14.649877Z",
     "iopub.status.busy": "2024-03-25T10:50:14.649354Z",
     "iopub.status.idle": "2024-03-25T10:50:14.656668Z",
     "shell.execute_reply": "2024-03-25T10:50:14.655841Z"
    },
    "papermill": {
     "duration": 0.017372,
     "end_time": "2024-03-25T10:50:14.658537",
     "exception": false,
     "start_time": "2024-03-25T10:50:14.641165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN_RNN_hybrid(nn.Module):\n",
    "    def __init__(self, cnn_block, rnn_block, feat_vec_size):\n",
    "        super(CNN_RNN_hybrid, self).__init__()\n",
    "        self.cnn_block = cnn_block\n",
    "        self.rnn_block = rnn_block\n",
    "        self.feat_vec_size = feat_vec_size\n",
    "        self.fc1 = nn.Linear(self.feat_vec_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #output of cnn block is (N,384)\n",
    "        x1 = x.view(-1,1, 16,20)\n",
    "        x1 = self.cnn_block(x1)\n",
    "        #output of rnn block is (N,M = 64)\n",
    "        x2 = self.rnn_block(x)\n",
    "        #concatenate the 2 outputs to produce a feat vec (N, M+384)\n",
    "        xx = torch.cat([x1, x2], dim = 1)\n",
    "        # pass through linear layers\n",
    "        xx = self.fc1(xx)\n",
    "        #final output is 4\n",
    "        xx = self.fc2(xx)\n",
    "        \n",
    "        return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1e87189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:14.674395Z",
     "iopub.status.busy": "2024-03-25T10:50:14.674129Z",
     "iopub.status.idle": "2024-03-25T10:50:14.684899Z",
     "shell.execute_reply": "2024-03-25T10:50:14.684014Z"
    },
    "papermill": {
     "duration": 0.020769,
     "end_time": "2024-03-25T10:50:14.686733",
     "exception": false,
     "start_time": "2024-03-25T10:50:14.665964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_RNN_hybrid(\n",
       "  (cnn_block): CNN_block(\n",
       "    (conv1): Conv2d(1, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (mxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "    (conv_total): Sequential(\n",
       "      (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (rnn_block): RNN_block(\n",
       "    (gru): GRU(20, 100, num_layers=8, batch_first=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=484, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN_RNN_hybrid(cnn_block, gru_block, 100+384)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2801630b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:14.703015Z",
     "iopub.status.busy": "2024-03-25T10:50:14.702734Z",
     "iopub.status.idle": "2024-03-25T10:50:14.707811Z",
     "shell.execute_reply": "2024-03-25T10:50:14.706916Z"
    },
    "papermill": {
     "duration": 0.015496,
     "end_time": "2024-03-25T10:50:14.709786",
     "exception": false,
     "start_time": "2024-03-25T10:50:14.694290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787140\n"
     ]
    }
   ],
   "source": [
    "#count the number of parameters in the model\n",
    "params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "print(sum(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f184b1",
   "metadata": {
    "papermill": {
     "duration": 0.007226,
     "end_time": "2024-03-25T10:50:14.724528",
     "exception": false,
     "start_time": "2024-03-25T10:50:14.717302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Shape Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0475998d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:14.740916Z",
     "iopub.status.busy": "2024-03-25T10:50:14.740504Z",
     "iopub.status.idle": "2024-03-25T10:50:14.858423Z",
     "shell.execute_reply": "2024-03-25T10:50:14.857516Z"
    },
    "papermill": {
     "duration": 0.128385,
     "end_time": "2024-03-25T10:50:14.860474",
     "exception": false,
     "start_time": "2024-03-25T10:50:14.732089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN BLOCK SHAPE TRACING\n",
      "Original shape of the image before passing through the network: \n",
      " torch.Size([16, 20])\n",
      "\n",
      "Reshape the size to take in account the batch number\n",
      "The new size is torch.Size([1, 16, 20])\n",
      "\n",
      "Shape of the image after passing through the GRU(20, 100, num_layers=8, batch_first=True): \n",
      " torch.Size([1, 16, 100])\n",
      "\n",
      "The final output shape is torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "X = X_train[0].to(device)\n",
    "y = y_train[0].to(device)\n",
    "print('RNN BLOCK SHAPE TRACING')\n",
    "print(f'Original shape of the image before passing through the network: \\n {X.shape}\\n')\n",
    "\n",
    "print('Reshape the size to take in account the batch number')\n",
    "X = X.view(1,16,20)\n",
    "print(f'The new size is {X.shape}\\n')\n",
    "\n",
    "h0 = torch.zeros(gru_block.L, X.size(0), gru_block.M).to(device)\n",
    "#c0 = torch.zeros(gru_block.L, X.size(0), gru_block.M).to(device)\n",
    "X, _ = gru_block.gru(X, h0)\n",
    "print(f'Shape of the image after passing through the {gru_block.gru}: \\n {X.shape}\\n')\n",
    "\n",
    "#get only the h(T) at the last time step\n",
    "Xg = X[:, -1, :]\n",
    "print(f'The final output shape is {Xg.shape}')\n",
    "#print(X)\n",
    "#print(f'Target: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8658299d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:14.877477Z",
     "iopub.status.busy": "2024-03-25T10:50:14.876902Z",
     "iopub.status.idle": "2024-03-25T10:50:15.263676Z",
     "shell.execute_reply": "2024-03-25T10:50:15.262779Z"
    },
    "papermill": {
     "duration": 0.39761,
     "end_time": "2024-03-25T10:50:15.265927",
     "exception": false,
     "start_time": "2024-03-25T10:50:14.868317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN BLOCK SHAPE TRACING\n",
      "Original shape of the image before passing through the network: \n",
      " torch.Size([16, 20])\n",
      "\n",
      "Reshape the size to take in account the batch number\n",
      "The new size is torch.Size([1, 1, 16, 20])\n",
      "\n",
      "Original shape of the image after passing through Sequential(\n",
      "  (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "): \n",
      " torch.Size([1, 64, 2, 3])\n",
      "\n",
      "Original shape of the image after passing through Flatten(start_dim=1, end_dim=-1): \n",
      " torch.Size([1, 384])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = X_train[0].to(device)\n",
    "print('CNN BLOCK SHAPE TRACING')\n",
    "print(f'Original shape of the image before passing through the network: \\n {X.shape}\\n')\n",
    "\n",
    "print('Reshape the size to take in account the batch number')\n",
    "X = X.view(1,1,16,20)\n",
    "print(f'The new size is {X.shape}\\n')\n",
    "\n",
    "X = cnn_block.conv_total(X)\n",
    "print(f'Original shape of the image after passing through {cnn_block.conv_total}: \\n {X.shape}\\n')\n",
    "\n",
    "#X = X.reshape(X.shape[0], -1)\n",
    "#print(f'After reshaping: {X.shape}') [1,384]\n",
    "Xc = cnn_block.flat(X)\n",
    "print(f'Original shape of the image after passing through {cnn_block.flat}: \\n {Xc.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a64a9537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:15.282980Z",
     "iopub.status.busy": "2024-03-25T10:50:15.282640Z",
     "iopub.status.idle": "2024-03-25T10:50:15.310878Z",
     "shell.execute_reply": "2024-03-25T10:50:15.309967Z"
    },
    "papermill": {
     "duration": 0.038737,
     "end_time": "2024-03-25T10:50:15.312736",
     "exception": false,
     "start_time": "2024-03-25T10:50:15.273999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 100]), torch.Size([1, 384]), torch.Size([1, 484]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat = torch.cat([Xc, Xg], dim=1) \n",
    "Xg.shape, Xc.shape, X_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5863a46e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:15.329881Z",
     "iopub.status.busy": "2024-03-25T10:50:15.329559Z",
     "iopub.status.idle": "2024-03-25T10:50:15.399602Z",
     "shell.execute_reply": "2024-03-25T10:50:15.398523Z"
    },
    "papermill": {
     "duration": 0.081001,
     "end_time": "2024-03-25T10:50:15.401761",
     "exception": false,
     "start_time": "2024-03-25T10:50:15.320760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-RNN HYBRID BLOCK SHAPE TRACING\n",
      "Original shape of the image before passing through the network: \n",
      " torch.Size([16, 20])\n",
      "\n",
      "Reshape the size to take in account the batch number\n",
      "The new size is torch.Size([1, 16, 20])\n",
      "\n",
      "Shape  after passing through the entire network: \n",
      " torch.Size([1, 4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = X_train[0].to(device)\n",
    "print('CNN-RNN HYBRID BLOCK SHAPE TRACING')\n",
    "print(f'Original shape of the image before passing through the network: \\n {X.shape}\\n')\n",
    "\n",
    "print('Reshape the size to take in account the batch number')\n",
    "X = X.view(1,16,20)\n",
    "print(f'The new size is {X.shape}\\n')\n",
    "\n",
    "X = model(X)\n",
    "print(f'Shape  after passing through the entire network: \\n {X.shape}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccdaf5d",
   "metadata": {
    "papermill": {
     "duration": 0.009759,
     "end_time": "2024-03-25T10:50:15.419777",
     "exception": false,
     "start_time": "2024-03-25T10:50:15.410018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train loop with scheduler\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "baab3240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:15.442406Z",
     "iopub.status.busy": "2024-03-25T10:50:15.441803Z",
     "iopub.status.idle": "2024-03-25T10:50:17.974464Z",
     "shell.execute_reply": "2024-03-25T10:50:17.973456Z"
    },
    "papermill": {
     "duration": 2.546506,
     "end_time": "2024-03-25T10:50:17.976929",
     "exception": false,
     "start_time": "2024-03-25T10:50:15.430423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_epoch = 200\n",
    "criterion = nn.MSELoss()\n",
    "batch_size = 128\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "#optimizer = torch.optim.SGD(model.parameters())\n",
    "\n",
    "#scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "#scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.01)\n",
    "scheduler = lr_scheduler.OneCycleLR(\n",
    "            optimizer=optimizer, epochs=max_epoch,\n",
    "            pct_start=0.0, steps_per_epoch=len(X_train)//batch_size,\n",
    "            max_lr= 0.01, div_factor=25, final_div_factor=4.0e-01\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c44641f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T10:50:17.995738Z",
     "iopub.status.busy": "2024-03-25T10:50:17.995266Z",
     "iopub.status.idle": "2024-03-25T13:18:22.558183Z",
     "shell.execute_reply": "2024-03-25T13:18:22.557228Z"
    },
    "papermill": {
     "duration": 8884.597472,
     "end_time": "2024-03-25T13:18:22.583132",
     "exception": false,
     "start_time": "2024-03-25T10:50:17.985660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200, train loss:  354.7113          test_loss:  280.9732, duration: 0:00:45.201048,           learning rate: (0.009999999999983262, 0.009999998669105229)\n",
      "Epoch: 2/200, train loss:  191.9631          test_loss:  164.7280, duration: 0:00:44.650546,           learning rate: (0.009999998669105229, 0.009999999540252078)\n",
      "Epoch: 3/200, train loss:  173.0056          test_loss:  170.6421, duration: 0:00:44.490430,           learning rate: (0.009999999540252078, 0.009999999506853922)\n",
      "Epoch: 4/200, train loss:  164.0047          test_loss:  182.2752, duration: 0:00:44.459396,           learning rate: (0.009999999506853922, 0.009999999437742407)\n",
      "Epoch: 5/200, train loss:  160.3681          test_loss:  180.7609, duration: 0:00:44.632498,           learning rate: (0.009999999437742407, 0.009999999446995155)\n",
      "Epoch: 6/200, train loss:  927.1545          test_loss:  919.9843, duration: 0:00:44.440628,           learning rate: (0.009999999446995155, 0.009999985801831913)\n",
      "Epoch: 7/200, train loss:  912.8172          test_loss:  907.0450, duration: 0:00:44.520208,           learning rate: (0.009999985801831913, 0.009999986197979632)\n",
      "Epoch: 8/200, train loss:  912.0878          test_loss:  913.8372, duration: 0:00:44.467758,           learning rate: (0.009999986197979632, 0.009999985990729914)\n",
      "Epoch: 9/200, train loss:  911.3763          test_loss:  904.8116, duration: 0:00:44.448775,           learning rate: (0.009999985990729914, 0.009999986265792446)\n",
      "Epoch: 10/200, train loss:  911.2175          test_loss:  905.5660, duration: 0:00:44.556412,           learning rate: (0.009999986265792446, 0.0099999862429048)\n",
      "Epoch: 11/200, train loss:  913.7065          test_loss:  924.0107, duration: 0:00:44.425706,           learning rate: (0.0099999862429048, 0.00999998567741471)\n",
      "Epoch: 12/200, train loss:  910.1394          test_loss:  905.2720, duration: 0:00:44.614969,           learning rate: (0.00999998567741471, 0.009999986251827422)\n",
      "Epoch: 13/200, train loss:  915.8535          test_loss:  921.7220, duration: 0:00:44.535701,           learning rate: (0.009999986251827422, 0.009999985748202714)\n",
      "Epoch: 14/200, train loss:  910.5179          test_loss:  904.7959, duration: 0:00:44.695285,           learning rate: (0.009999985748202714, 0.009999986266267694)\n",
      "Epoch: 15/200, train loss:  910.8283          test_loss:  905.1090, duration: 0:00:44.371982,           learning rate: (0.009999986266267694, 0.009999986256770801)\n",
      "Epoch: 16/200, train loss:  919.9859          test_loss:  904.4675, duration: 0:00:44.433082,           learning rate: (0.009999986256770801, 0.00999998627622389)\n",
      "Epoch: 17/200, train loss:  910.5877          test_loss:  905.3369, duration: 0:00:44.595928,           learning rate: (0.00999998627622389, 0.009999986249857332)\n",
      "Epoch: 18/200, train loss:  930.4558          test_loss:  907.2004, duration: 0:00:44.462164,           learning rate: (0.009999986249857332, 0.009999986193257027)\n",
      "Epoch: 19/200, train loss:  911.6543          test_loss:  917.1715, duration: 0:00:44.372256,           learning rate: (0.009999986193257027, 0.009999985888423726)\n",
      "Epoch: 20/200, train loss:  915.1743          test_loss:  904.4456, duration: 0:00:44.359190,           learning rate: (0.009999985888423726, 0.009999986276888646)\n",
      "Epoch: 21/200, train loss:  910.9978          test_loss:  904.7157, duration: 0:00:44.319340,           learning rate: (0.009999986276888646, 0.009999986268700412)\n",
      "Epoch: 22/200, train loss:  911.6046          test_loss:  905.0315, duration: 0:00:44.336716,           learning rate: (0.009999986268700412, 0.009999986259121862)\n",
      "Epoch: 23/200, train loss:  932.8601          test_loss:  951.8807, duration: 0:00:44.293575,           learning rate: (0.009999986259121862, 0.009999984801353473)\n",
      "Epoch: 24/200, train loss:  911.5252          test_loss:  908.7572, duration: 0:00:44.325871,           learning rate: (0.009999984801353473, 0.009999986145882194)\n",
      "Epoch: 25/200, train loss:  930.9305          test_loss:  929.7243, duration: 0:00:44.417723,           learning rate: (0.009999986145882194, 0.009999985499934649)\n",
      "Epoch: 26/200, train loss:  913.9551          test_loss:  910.2074, duration: 0:00:44.525445,           learning rate: (0.009999985499934649, 0.00999998610167786)\n",
      "Epoch: 27/200, train loss:  912.0417          test_loss:  909.1737, duration: 0:00:44.452202,           learning rate: (0.00999998610167786, 0.009999986133194118)\n",
      "Epoch: 28/200, train loss:  919.7514          test_loss:  839.3291, duration: 0:00:44.486642,           learning rate: (0.009999986133194118, 0.00999998817974836)\n",
      "Epoch: 29/200, train loss:  897.1137          test_loss:  908.5974, duration: 0:00:44.571840,           learning rate: (0.00999998817974836, 0.009999986150748909)\n",
      "Epoch: 30/200, train loss:  918.4070          test_loss:  906.1624, duration: 0:00:44.554110,           learning rate: (0.009999986150748909, 0.00999998622479728)\n",
      "Epoch: 31/200, train loss:  911.7641          test_loss:  926.3059, duration: 0:00:44.442768,           learning rate: (0.00999998622479728, 0.009999985606251555)\n",
      "Epoch: 32/200, train loss:  920.3663          test_loss:  905.8345, duration: 0:00:44.448817,           learning rate: (0.009999985606251555, 0.009999986234755592)\n",
      "Epoch: 33/200, train loss:  911.3777          test_loss:  909.5394, duration: 0:00:44.604716,           learning rate: (0.009999986234755592, 0.00999998612204812)\n",
      "Epoch: 34/200, train loss:  921.5112          test_loss:  906.6706, duration: 0:00:44.592907,           learning rate: (0.00999998612204812, 0.00999998620935997)\n",
      "Epoch: 35/200, train loss:  911.1909          test_loss:  909.8165, duration: 0:00:44.147383,           learning rate: (0.00999998620935997, 0.00999998611360058)\n",
      "Epoch: 36/200, train loss:  918.9504          test_loss:  908.0624, duration: 0:00:44.485280,           learning rate: (0.00999998611360058, 0.0099999861670358)\n",
      "Epoch: 37/200, train loss:  911.3008          test_loss:  908.4094, duration: 0:00:44.475140,           learning rate: (0.0099999861670358, 0.009999986156471161)\n",
      "Epoch: 38/200, train loss:  911.6968          test_loss:  905.4837, duration: 0:00:44.543727,           learning rate: (0.009999986156471161, 0.009999986245401517)\n",
      "Epoch: 39/200, train loss:  911.1250          test_loss:  913.3414, duration: 0:00:44.239017,           learning rate: (0.009999986245401517, 0.009999986005911385)\n",
      "Epoch: 40/200, train loss:  911.2029          test_loss:  906.9004, duration: 0:00:44.480288,           learning rate: (0.009999986005911385, 0.009999986202374852)\n",
      "Epoch: 41/200, train loss:  910.2773          test_loss:  905.2458, duration: 0:00:44.550982,           learning rate: (0.009999986202374852, 0.009999986252620115)\n",
      "Epoch: 42/200, train loss:  918.0328          test_loss:  905.6159, duration: 0:00:44.532766,           learning rate: (0.009999986252620115, 0.009999986241390514)\n",
      "Epoch: 43/200, train loss:  910.4291          test_loss:  909.6754, duration: 0:00:44.405135,           learning rate: (0.009999986241390514, 0.009999986117902267)\n",
      "Epoch: 44/200, train loss:  911.3628          test_loss:  907.2551, duration: 0:00:44.309764,           learning rate: (0.009999986117902267, 0.00999998619159198)\n",
      "Epoch: 45/200, train loss:  910.9208          test_loss:  907.3039, duration: 0:00:44.469144,           learning rate: (0.00999998619159198, 0.009999986190108178)\n",
      "Epoch: 46/200, train loss:  910.9473          test_loss:  906.9546, duration: 0:00:44.397254,           learning rate: (0.009999986190108178, 0.0099999862007294)\n",
      "Epoch: 47/200, train loss:  924.9174          test_loss:  904.3102, duration: 0:00:44.254109,           learning rate: (0.0099999862007294, 0.00999998628099091)\n",
      "Epoch: 48/200, train loss:  910.4708          test_loss:  915.6817, duration: 0:00:44.408594,           learning rate: (0.00999998628099091, 0.0099999859341799)\n",
      "Epoch: 49/200, train loss:  930.2582          test_loss:  910.4945, duration: 0:00:44.348973,           learning rate: (0.0099999859341799, 0.009999986092918873)\n",
      "Epoch: 50/200, train loss:  911.4279          test_loss:  908.6057, duration: 0:00:44.402797,           learning rate: (0.009999986092918873, 0.009999986150493936)\n",
      "Epoch: 51/200, train loss:  910.8010          test_loss:  911.3847, duration: 0:00:44.288450,           learning rate: (0.009999986150493936, 0.009999986065739926)\n",
      "Epoch: 52/200, train loss:  920.7057          test_loss:  906.7996, duration: 0:00:44.468057,           learning rate: (0.009999986065739926, 0.00999998620544025)\n",
      "Epoch: 53/200, train loss:  910.8456          test_loss:  906.7146, duration: 0:00:44.544413,           learning rate: (0.00999998620544025, 0.00999998620802309)\n",
      "Epoch: 54/200, train loss:  911.8266          test_loss:  905.6814, duration: 0:00:44.532634,           learning rate: (0.00999998620802309, 0.00999998623940319)\n",
      "Epoch: 55/200, train loss:  919.2731          test_loss:  905.3066, duration: 0:00:44.352681,           learning rate: (0.00999998623940319, 0.009999986250776218)\n",
      "Epoch: 56/200, train loss:  911.5713          test_loss:  907.4138, duration: 0:00:44.462341,           learning rate: (0.009999986250776218, 0.00999998618676829)\n",
      "Epoch: 57/200, train loss:  911.3341          test_loss:  904.8458, duration: 0:00:44.511619,           learning rate: (0.00999998618676829, 0.009999986264754498)\n",
      "Epoch: 58/200, train loss:  914.6404          test_loss:  909.6512, duration: 0:00:44.404955,           learning rate: (0.009999986264754498, 0.009999986118639372)\n",
      "Epoch: 59/200, train loss:  910.5207          test_loss:  911.8180, duration: 0:00:44.420867,           learning rate: (0.009999986118639372, 0.009999986052502262)\n",
      "Epoch: 60/200, train loss:  911.8950          test_loss:  905.8414, duration: 0:00:44.552979,           learning rate: (0.009999986052502262, 0.009999986234543842)\n",
      "Epoch: 61/200, train loss:  911.1120          test_loss:  930.6740, duration: 0:00:44.486181,           learning rate: (0.009999986234543842, 0.009999985470326374)\n",
      "Epoch: 62/200, train loss:  913.4294          test_loss:  905.6002, duration: 0:00:44.397644,           learning rate: (0.009999985470326374, 0.009999986241866043)\n",
      "Epoch: 63/200, train loss:  911.6068          test_loss:  904.3953, duration: 0:00:44.280876,           learning rate: (0.009999986241866043, 0.009999986278411626)\n",
      "Epoch: 64/200, train loss:  911.3851          test_loss:  909.6473, duration: 0:00:44.461486,           learning rate: (0.009999986278411626, 0.009999986118758613)\n",
      "Epoch: 65/200, train loss:  911.3279          test_loss:  911.2128, duration: 0:00:44.529925,           learning rate: (0.009999986118758613, 0.009999986070990265)\n",
      "Epoch: 66/200, train loss:  911.1968          test_loss:  903.9347, duration: 0:00:44.567730,           learning rate: (0.009999986070990265, 0.009999986292368642)\n",
      "Epoch: 67/200, train loss:  926.6101          test_loss:  914.5508, duration: 0:00:44.304157,           learning rate: (0.009999986292368642, 0.009999985968866677)\n",
      "Epoch: 68/200, train loss:  911.8915          test_loss:  913.1040, duration: 0:00:44.316876,           learning rate: (0.009999985968866677, 0.009999986013175106)\n",
      "Epoch: 69/200, train loss:  911.5909          test_loss:  914.1681, duration: 0:00:44.549925,           learning rate: (0.009999986013175106, 0.009999985980594692)\n",
      "Epoch: 70/200, train loss:  932.2002          test_loss:  907.9024, duration: 0:00:44.511439,           learning rate: (0.009999985980594692, 0.00999998617190527)\n",
      "Epoch: 71/200, train loss:  911.3640          test_loss:  908.5120, duration: 0:00:44.302682,           learning rate: (0.00999998617190527, 0.009999986153347844)\n",
      "Epoch: 72/200, train loss:  911.9015          test_loss:  910.5266, duration: 0:00:44.466927,           learning rate: (0.009999986153347844, 0.009999986091937647)\n",
      "Epoch: 73/200, train loss:  912.5448          test_loss:  940.3878, duration: 0:00:44.525924,           learning rate: (0.009999986091937647, 0.009999985165769928)\n",
      "Epoch: 74/200, train loss:  912.0029          test_loss:  910.2501, duration: 0:00:44.415439,           learning rate: (0.009999985165769928, 0.009999986100375828)\n",
      "Epoch: 75/200, train loss:  911.2176          test_loss:  904.7109, duration: 0:00:44.256108,           learning rate: (0.009999986100375828, 0.009999986268844775)\n",
      "Epoch: 76/200, train loss:  911.3730          test_loss:  904.5655, duration: 0:00:44.501335,           learning rate: (0.009999986268844775, 0.009999986273253856)\n",
      "Epoch: 77/200, train loss:  925.1642          test_loss:  904.2649, duration: 0:00:44.491400,           learning rate: (0.009999986273253856, 0.009999986282365213)\n",
      "Epoch: 78/200, train loss:  890.0334          test_loss:  946.1840, duration: 0:00:44.459562,           learning rate: (0.009999986282365213, 0.009999984982535858)\n",
      "Epoch: 79/200, train loss:  912.4134          test_loss:  936.6418, duration: 0:00:44.363266,           learning rate: (0.009999984982535858, 0.009999985283593065)\n",
      "Epoch: 80/200, train loss:  915.1059          test_loss:  905.7732, duration: 0:00:44.516916,           learning rate: (0.009999985283593065, 0.0099999862366144)\n",
      "Epoch: 81/200, train loss:  912.4114          test_loss:  909.9021, duration: 0:00:44.513897,           learning rate: (0.0099999862366144, 0.009999986110989418)\n",
      "Epoch: 82/200, train loss:  912.4986          test_loss:  920.1630, duration: 0:00:44.390549,           learning rate: (0.009999986110989418, 0.0099999857963202)\n",
      "Epoch: 83/200, train loss:  924.4852          test_loss:  905.7329, duration: 0:00:44.373836,           learning rate: (0.0099999857963202, 0.009999986237839532)\n",
      "Epoch: 84/200, train loss:  910.8288          test_loss:  912.3143, duration: 0:00:44.487142,           learning rate: (0.009999986237839532, 0.009999986037333347)\n",
      "Epoch: 85/200, train loss:  910.5450          test_loss:  909.1918, duration: 0:00:44.455806,           learning rate: (0.009999986037333347, 0.009999986132643059)\n",
      "Epoch: 86/200, train loss:  909.9140          test_loss:  906.9081, duration: 0:00:44.570976,           learning rate: (0.009999986132643059, 0.009999986202140952)\n",
      "Epoch: 87/200, train loss:  909.8436          test_loss:  905.6820, duration: 0:00:44.230195,           learning rate: (0.009999986202140952, 0.009999986239384879)\n",
      "Epoch: 88/200, train loss:  910.0371          test_loss:  909.2886, duration: 0:00:44.394160,           learning rate: (0.009999986239384879, 0.009999986129690733)\n",
      "Epoch: 89/200, train loss:  930.8906          test_loss:  908.0965, duration: 0:00:44.334543,           learning rate: (0.009999986129690733, 0.009999986165995782)\n",
      "Epoch: 90/200, train loss:  910.4959          test_loss:  916.6195, duration: 0:00:44.322948,           learning rate: (0.009999986165995782, 0.009999985905387723)\n",
      "Epoch: 91/200, train loss:  909.9769          test_loss:  917.3332, duration: 0:00:44.312001,           learning rate: (0.009999985905387723, 0.009999985883452852)\n",
      "Epoch: 92/200, train loss:  910.5205          test_loss:  917.6922, duration: 0:00:44.236284,           learning rate: (0.009999985883452852, 0.009999985872414796)\n",
      "Epoch: 93/200, train loss:  910.3607          test_loss:  904.2632, duration: 0:00:44.421897,           learning rate: (0.009999985872414796, 0.00999998628241704)\n",
      "Epoch: 94/200, train loss:  910.3270          test_loss:  906.1779, duration: 0:00:44.510541,           learning rate: (0.00999998628241704, 0.009999986224326147)\n",
      "Epoch: 95/200, train loss:  910.7039          test_loss:  905.6125, duration: 0:00:44.285125,           learning rate: (0.009999986224326147, 0.00999998624149339)\n",
      "Epoch: 96/200, train loss:  910.5260          test_loss:  924.8839, duration: 0:00:44.328476,           learning rate: (0.00999998624149339, 0.009999985650363048)\n",
      "Epoch: 97/200, train loss:  909.9606          test_loss:  913.1301, duration: 0:00:44.361718,           learning rate: (0.009999985650363048, 0.00999998601237654)\n",
      "Epoch: 98/200, train loss:  935.0561          test_loss:  905.4957, duration: 0:00:44.340046,           learning rate: (0.00999998601237654, 0.009999986245038953)\n",
      "Epoch: 99/200, train loss:  911.3776          test_loss:  905.6938, duration: 0:00:44.253185,           learning rate: (0.009999986245038953, 0.009999986239024768)\n",
      "Epoch: 100/200, train loss:  911.6241          test_loss:  905.6407, duration: 0:00:44.476853,           learning rate: (0.009999986239024768, 0.009999986240637845)\n",
      "Epoch: 101/200, train loss:  914.7277          test_loss:  907.0264, duration: 0:00:44.330870,           learning rate: (0.009999986240637845, 0.009999986198546761)\n",
      "Epoch: 102/200, train loss:  912.1013          test_loss:  905.8430, duration: 0:00:44.415482,           learning rate: (0.009999986198546761, 0.00999998623449705)\n",
      "Epoch: 103/200, train loss:  912.0033          test_loss:  905.1500, duration: 0:00:44.282795,           learning rate: (0.00999998623449705, 0.009999986255526543)\n",
      "Epoch: 104/200, train loss:  915.3894          test_loss:  907.4768, duration: 0:00:44.483756,           learning rate: (0.009999986255526543, 0.009999986184851106)\n",
      "Epoch: 105/200, train loss:  911.5147          test_loss:  906.8795, duration: 0:00:44.355076,           learning rate: (0.009999986184851106, 0.009999986203011148)\n",
      "Epoch: 106/200, train loss:  922.6507          test_loss:  904.2976, duration: 0:00:44.371831,           learning rate: (0.009999986203011148, 0.009999986281374187)\n",
      "Epoch: 107/200, train loss:  911.3370          test_loss:  908.5558, duration: 0:00:44.265720,           learning rate: (0.009999986281374187, 0.009999986152016128)\n",
      "Epoch: 108/200, train loss:  916.3419          test_loss:  906.3644, duration: 0:00:44.351471,           learning rate: (0.009999986152016128, 0.009999986218663652)\n",
      "Epoch: 109/200, train loss:  910.5793          test_loss:  904.4152, duration: 0:00:44.331737,           learning rate: (0.009999986218663652, 0.009999986277810263)\n",
      "Epoch: 110/200, train loss:  910.9476          test_loss:  929.3652, duration: 0:00:44.384346,           learning rate: (0.009999986277810263, 0.009999985511120777)\n",
      "Epoch: 111/200, train loss:  915.9323          test_loss:  909.3716, duration: 0:00:44.314391,           learning rate: (0.009999985511120777, 0.009999986127162973)\n",
      "Epoch: 112/200, train loss:  910.9231          test_loss:  950.5561, duration: 0:00:44.441129,           learning rate: (0.009999986127162973, 0.00999998484357938)\n",
      "Epoch: 113/200, train loss:  943.6935          test_loss:  904.8310, duration: 0:00:44.438811,           learning rate: (0.00999998484357938, 0.009999986265202657)\n",
      "Epoch: 114/200, train loss:  909.1391          test_loss:  939.1748, duration: 0:00:44.765681,           learning rate: (0.009999986265202657, 0.009999985203973764)\n",
      "Epoch: 115/200, train loss:  913.9090          test_loss:  904.4848, duration: 0:00:44.485400,           learning rate: (0.009999985203973764, 0.009999986275699528)\n",
      "Epoch: 116/200, train loss:  910.8421          test_loss:  910.4284, duration: 0:00:44.517643,           learning rate: (0.009999986275699528, 0.009999986094935999)\n",
      "Epoch: 117/200, train loss:  910.9773          test_loss:  912.6378, duration: 0:00:44.433119,           learning rate: (0.009999986094935999, 0.009999986027438956)\n",
      "Epoch: 118/200, train loss:  926.6850          test_loss:  905.0176, duration: 0:00:44.502699,           learning rate: (0.009999986027438956, 0.009999986259543816)\n",
      "Epoch: 119/200, train loss:  912.2373          test_loss:  916.9298, duration: 0:00:44.364846,           learning rate: (0.009999986259543816, 0.009999985895853554)\n",
      "Epoch: 120/200, train loss:  916.5442          test_loss:  906.2450, duration: 0:00:44.458534,           learning rate: (0.009999985895853554, 0.009999986222290733)\n",
      "Epoch: 121/200, train loss:  911.0985          test_loss:  911.4921, duration: 0:00:44.500945,           learning rate: (0.009999986222290733, 0.009999986062459932)\n",
      "Epoch: 122/200, train loss:  911.6101          test_loss:  910.4706, duration: 0:00:44.547347,           learning rate: (0.009999986062459932, 0.00999998609364888)\n",
      "Epoch: 123/200, train loss:  911.4863          test_loss:  905.9396, duration: 0:00:44.357203,           learning rate: (0.00999998609364888, 0.009999986231564728)\n",
      "Epoch: 124/200, train loss:  926.9987          test_loss:  932.1270, duration: 0:00:44.464468,           learning rate: (0.009999986231564728, 0.00999998542497093)\n",
      "Epoch: 125/200, train loss:  911.9011          test_loss:  911.8310, duration: 0:00:44.516787,           learning rate: (0.00999998542497093, 0.009999986052104101)\n",
      "Epoch: 126/200, train loss:  911.8810          test_loss:  951.8735, duration: 0:00:44.588323,           learning rate: (0.009999986052104101, 0.009999984801582998)\n",
      "Epoch: 127/200, train loss:  917.4891          test_loss:  904.4289, duration: 0:00:44.398552,           learning rate: (0.009999984801582998, 0.009999986277393295)\n",
      "Epoch: 128/200, train loss:  911.7784          test_loss:  906.9987, duration: 0:00:44.319518,           learning rate: (0.009999986277393295, 0.009999986199389261)\n",
      "Epoch: 129/200, train loss:  919.5091          test_loss:  911.7759, duration: 0:00:44.322710,           learning rate: (0.009999986199389261, 0.00999998605378951)\n",
      "Epoch: 130/200, train loss:  910.2875          test_loss:  905.3374, duration: 0:00:44.362362,           learning rate: (0.00999998605378951, 0.009999986249840456)\n",
      "Epoch: 131/200, train loss:  917.0746          test_loss:  907.7817, duration: 0:00:44.243361,           learning rate: (0.009999986249840456, 0.0099999861755765)\n",
      "Epoch: 132/200, train loss:  910.1160          test_loss:  906.7326, duration: 0:00:44.206883,           learning rate: (0.0099999861755765, 0.00999998620747574)\n",
      "Epoch: 133/200, train loss:  909.9546          test_loss:  926.4125, duration: 0:00:44.355267,           learning rate: (0.00999998620747574, 0.009999985602942654)\n",
      "Epoch: 134/200, train loss:  921.0842          test_loss:  904.5127, duration: 0:00:44.476212,           learning rate: (0.009999985602942654, 0.009999986274853715)\n",
      "Epoch: 135/200, train loss:  909.8938          test_loss:  905.5776, duration: 0:00:44.385120,           learning rate: (0.009999986274853715, 0.00999998624255221)\n",
      "Epoch: 136/200, train loss:  912.5635          test_loss:  911.9596, duration: 0:00:44.469714,           learning rate: (0.00999998624255221, 0.009999986048173797)\n",
      "Epoch: 137/200, train loss:  909.7959          test_loss:  904.8382, duration: 0:00:44.547687,           learning rate: (0.009999986048173797, 0.00999998626498572)\n",
      "Epoch: 138/200, train loss:  910.7369          test_loss:  911.6786, duration: 0:00:44.593966,           learning rate: (0.00999998626498572, 0.009999986056762826)\n",
      "Epoch: 139/200, train loss:  910.2362          test_loss:  907.3432, duration: 0:00:44.287118,           learning rate: (0.009999986056762826, 0.009999986188914293)\n",
      "Epoch: 140/200, train loss:  910.0262          test_loss:  907.1589, duration: 0:00:44.284901,           learning rate: (0.009999986188914293, 0.00999998619451703)\n",
      "Epoch: 141/200, train loss:  909.8936          test_loss:  912.0544, duration: 0:00:44.359926,           learning rate: (0.00999998619451703, 0.009999986045278974)\n",
      "Epoch: 142/200, train loss:  910.1742          test_loss:  904.3854, duration: 0:00:44.296088,           learning rate: (0.009999986045278974, 0.009999986278712944)\n",
      "Epoch: 143/200, train loss:  909.9712          test_loss:  910.4502, duration: 0:00:44.468903,           learning rate: (0.009999986278712944, 0.00999998609427067)\n",
      "Epoch: 144/200, train loss:  910.1219          test_loss:  910.6670, duration: 0:00:44.564750,           learning rate: (0.00999998609427067, 0.00999998608765288)\n",
      "Epoch: 145/200, train loss:  913.6076          test_loss:  913.9492, duration: 0:00:44.681977,           learning rate: (0.00999998608765288, 0.009999985987298302)\n",
      "Epoch: 146/200, train loss:  914.5909          test_loss:  904.5244, duration: 0:00:44.435670,           learning rate: (0.009999985987298302, 0.009999986274500019)\n",
      "Epoch: 147/200, train loss:  911.7019          test_loss:  905.3479, duration: 0:00:44.371800,           learning rate: (0.009999986274500019, 0.009999986249522468)\n",
      "Epoch: 148/200, train loss:  912.2433          test_loss:  914.8599, duration: 0:00:44.312151,           learning rate: (0.009999986249522468, 0.0099999859593892)\n",
      "Epoch: 149/200, train loss:  911.5659          test_loss:  900.2577, duration: 0:00:44.412083,           learning rate: (0.0099999859593892, 0.009999986403539947)\n",
      "Epoch: 150/200, train loss:  905.6828          test_loss:  910.3049, duration: 0:00:44.556017,           learning rate: (0.009999986403539947, 0.009999986098702257)\n",
      "Epoch: 151/200, train loss:  911.7935          test_loss:  911.9704, duration: 0:00:44.218746,           learning rate: (0.009999986098702257, 0.009999986047844796)\n",
      "Epoch: 152/200, train loss:  911.5881          test_loss:  922.3529, duration: 0:00:44.259481,           learning rate: (0.009999986047844796, 0.009999985728706022)\n",
      "Epoch: 153/200, train loss:  926.2451          test_loss:  917.4641, duration: 0:00:44.378540,           learning rate: (0.009999985728706022, 0.009999985879427534)\n",
      "Epoch: 154/200, train loss:  912.1416          test_loss:  904.4358, duration: 0:00:44.376812,           learning rate: (0.009999985879427534, 0.009999986277183508)\n",
      "Epoch: 155/200, train loss:  920.8175          test_loss:  915.5471, duration: 0:00:44.525125,           learning rate: (0.009999986277183508, 0.009999985938311393)\n",
      "Epoch: 156/200, train loss:  911.1369          test_loss:  910.9569, duration: 0:00:44.376251,           learning rate: (0.009999985938311393, 0.009999986078805475)\n",
      "Epoch: 157/200, train loss:  910.4682          test_loss:  904.8906, duration: 0:00:44.494455,           learning rate: (0.009999986078805475, 0.009999986263393823)\n",
      "Epoch: 158/200, train loss:  931.6293          test_loss:  921.1291, duration: 0:00:44.343106,           learning rate: (0.009999986263393823, 0.009999985766512787)\n",
      "Epoch: 159/200, train loss:  917.8445          test_loss:  905.6875, duration: 0:00:44.177774,           learning rate: (0.009999985766512787, 0.009999986239217086)\n",
      "Epoch: 160/200, train loss:  910.9616          test_loss:  921.6637, duration: 0:00:44.367916,           learning rate: (0.009999986239217086, 0.009999985750004863)\n",
      "Epoch: 161/200, train loss:  910.4417          test_loss:  911.2955, duration: 0:00:44.351013,           learning rate: (0.009999985750004863, 0.009999986068464965)\n",
      "Epoch: 162/200, train loss:  911.3895          test_loss:  938.5922, duration: 0:00:44.421228,           learning rate: (0.009999986068464965, 0.00999998522230643)\n",
      "Epoch: 163/200, train loss:  910.7824          test_loss:  907.4419, duration: 0:00:44.327189,           learning rate: (0.00999998522230643, 0.009999986185911126)\n",
      "Epoch: 164/200, train loss:  910.5000          test_loss:  906.7669, duration: 0:00:44.414047,           learning rate: (0.009999986185911126, 0.00999998620643204)\n",
      "Epoch: 165/200, train loss:  910.1098          test_loss:  906.7508, duration: 0:00:44.607841,           learning rate: (0.00999998620643204, 0.00999998620692404)\n",
      "Epoch: 166/200, train loss:  910.2598          test_loss:  905.4568, duration: 0:00:44.503132,           learning rate: (0.00999998620692404, 0.009999986246217295)\n",
      "Epoch: 167/200, train loss:  910.4744          test_loss:  905.4307, duration: 0:00:44.506135,           learning rate: (0.009999986246217295, 0.0099999862470097)\n",
      "Epoch: 168/200, train loss:  910.3571          test_loss:  905.9046, duration: 0:00:44.508933,           learning rate: (0.0099999862470097, 0.009999986232627683)\n",
      "Epoch: 169/200, train loss:  913.9284          test_loss:  905.0611, duration: 0:00:44.430847,           learning rate: (0.009999986232627683, 0.0099999862582241)\n",
      "Epoch: 170/200, train loss:  910.7444          test_loss:  904.9139, duration: 0:00:44.257544,           learning rate: (0.0099999862582241, 0.00999998626268983)\n",
      "Epoch: 171/200, train loss:  927.0789          test_loss:  905.8542, duration: 0:00:44.152826,           learning rate: (0.00999998626268983, 0.009999986234155565)\n",
      "Epoch: 172/200, train loss:  911.1898          test_loss:  907.5383, duration: 0:00:44.458802,           learning rate: (0.009999986234155565, 0.009999986182981722)\n",
      "Epoch: 173/200, train loss:  911.1995          test_loss:  909.7640, duration: 0:00:44.570057,           learning rate: (0.009999986182981722, 0.009999986115200976)\n",
      "Epoch: 174/200, train loss:  915.7181          test_loss:  905.7493, duration: 0:00:44.447177,           learning rate: (0.009999986115200976, 0.00999998623734008)\n",
      "Epoch: 175/200, train loss:  911.3526          test_loss:  911.8304, duration: 0:00:44.256732,           learning rate: (0.00999998623734008, 0.009999986052123915)\n",
      "Epoch: 176/200, train loss:  918.2729          test_loss:  903.8333, duration: 0:00:44.291077,           learning rate: (0.009999986052123915, 0.009999986295441604)\n",
      "Epoch: 177/200, train loss:  911.3264          test_loss:  906.1600, duration: 0:00:44.488754,           learning rate: (0.009999986295441604, 0.009999986224869712)\n",
      "Epoch: 178/200, train loss:  910.9453          test_loss:  914.1498, duration: 0:00:44.356890,           learning rate: (0.009999986224869712, 0.009999985981154487)\n",
      "Epoch: 179/200, train loss:  910.8174          test_loss:  906.6980, duration: 0:00:44.220924,           learning rate: (0.009999985981154487, 0.009999986208525786)\n",
      "Epoch: 180/200, train loss:  910.3023          test_loss:  910.7481, duration: 0:00:44.167179,           learning rate: (0.009999986208525786, 0.00999998608517838)\n",
      "Epoch: 181/200, train loss:  910.2584          test_loss:  912.2043, duration: 0:00:44.270677,           learning rate: (0.00999998608517838, 0.00999998604069649)\n",
      "Epoch: 182/200, train loss:  910.4340          test_loss:  909.7379, duration: 0:00:44.255764,           learning rate: (0.00999998604069649, 0.009999986115997915)\n",
      "Epoch: 183/200, train loss:  910.1975          test_loss:  911.7128, duration: 0:00:44.217799,           learning rate: (0.009999986115997915, 0.009999986055717714)\n",
      "Epoch: 184/200, train loss:  910.3667          test_loss:  915.1917, duration: 0:00:44.360179,           learning rate: (0.009999986055717714, 0.009999985949213471)\n",
      "Epoch: 185/200, train loss:  912.4182          test_loss:  915.0794, duration: 0:00:44.344181,           learning rate: (0.009999985949213471, 0.009999985952658188)\n",
      "Epoch: 186/200, train loss:  910.4105          test_loss:  907.7496, duration: 0:00:44.463970,           learning rate: (0.009999985952658188, 0.009999986176552157)\n",
      "Epoch: 187/200, train loss:  910.5488          test_loss:  904.1309, duration: 0:00:44.201702,           learning rate: (0.009999986176552157, 0.009999986286424407)\n",
      "Epoch: 188/200, train loss:  955.5061          test_loss:  911.1150, duration: 0:00:44.525875,           learning rate: (0.009999986286424407, 0.009999986073978291)\n",
      "Epoch: 189/200, train loss:  913.2005          test_loss:  909.7273, duration: 0:00:44.317929,           learning rate: (0.009999986073978291, 0.009999986116320934)\n",
      "Epoch: 190/200, train loss:  912.1063          test_loss:  906.9954, duration: 0:00:44.403872,           learning rate: (0.009999986116320934, 0.009999986199488168)\n",
      "Epoch: 191/200, train loss:  912.6316          test_loss:  911.0640, duration: 0:00:44.517630,           learning rate: (0.009999986199488168, 0.009999986075535115)\n",
      "Epoch: 192/200, train loss:  911.5553          test_loss:  904.9104, duration: 0:00:44.526509,           learning rate: (0.009999986075535115, 0.009999986262793862)\n",
      "Epoch: 193/200, train loss:  911.0431          test_loss:  920.1130, duration: 0:00:44.499810,           learning rate: (0.009999986262793862, 0.00999998579786127)\n",
      "Epoch: 194/200, train loss:  921.2125          test_loss:  904.3758, duration: 0:00:44.416784,           learning rate: (0.00999998579786127, 0.009999986279003076)\n",
      "Epoch: 195/200, train loss:  912.1162          test_loss:  921.7744, duration: 0:00:44.225063,           learning rate: (0.009999986279003076, 0.00999998574658394)\n",
      "Epoch: 196/200, train loss:  913.0753          test_loss:  926.8440, duration: 0:00:44.349579,           learning rate: (0.00999998574658394, 0.009999985589541474)\n",
      "Epoch: 197/200, train loss:  912.1440          test_loss:  908.0001, duration: 0:00:44.453435,           learning rate: (0.009999985589541474, 0.00999998616893166)\n",
      "Epoch: 198/200, train loss:  946.8122          test_loss:  901.7398, duration: 0:00:44.656342,           learning rate: (0.00999998616893166, 0.009999986358784033)\n",
      "Epoch: 199/200, train loss:  900.9976          test_loss:  910.6545, duration: 0:00:44.426415,           learning rate: (0.009999986358784033, 0.009999986088036667)\n",
      "Epoch: 200/200, train loss:  911.0551          test_loss:  904.6333, duration: 0:00:44.458057,           learning rate: (0.009999986088036667, 0.009999986271197359)\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses=batch_gd_scheduler(model, criterion, optimizer, train_gen, test_gen, scheduler, \n",
    "                                             max_epoch, device,  cnn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d196747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:18:22.631571Z",
     "iopub.status.busy": "2024-03-25T13:18:22.631247Z",
     "iopub.status.idle": "2024-03-25T13:18:44.532018Z",
     "shell.execute_reply": "2024-03-25T13:18:44.530975Z"
    },
    "papermill": {
     "duration": 21.927456,
     "end_time": "2024-03-25T13:18:44.534204",
     "exception": false,
     "start_time": "2024-03-25T13:18:22.606748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for h11:0.1441, Test accuracy for h11: 0.1436\n",
      "Train accuracy for h21:0.1344, Test accuracy for h21: 0.1336\n",
      "Train accuracy for h31:0.0402, Test accuracy for h31: 0.0399\n",
      "Train accuracy for h22:0.0000, Test accuracy for h22: 0.0000\n"
     ]
    }
   ],
   "source": [
    "train_acc, test_acc = calc_accuracy_mr(model, train_gen , test_gen, device = device, cnn= False)\n",
    "print(f'Train accuracy for h11:{train_acc[0]:.4f}, Test accuracy for h11: {test_acc[0]:.4f}')\n",
    "print(f'Train accuracy for h21:{train_acc[1]:.4f}, Test accuracy for h21: {test_acc[1]:.4f}')\n",
    "print(f'Train accuracy for h31:{train_acc[2]:.4f}, Test accuracy for h31: {test_acc[2]:.4f}')\n",
    "print(f'Train accuracy for h22:{train_acc[3]:.4f}, Test accuracy for h22: {test_acc[3]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71ee75b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:18:44.582408Z",
     "iopub.status.busy": "2024-03-25T13:18:44.582129Z",
     "iopub.status.idle": "2024-03-25T13:18:44.598069Z",
     "shell.execute_reply": "2024-03-25T13:18:44.597337Z"
    },
    "papermill": {
     "duration": 0.041822,
     "end_time": "2024-03-25T13:18:44.599893",
     "exception": false,
     "start_time": "2024-03-25T13:18:44.558071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, '/kaggle/working/saved_models/CNN_GRU_hybrid_cicy4_Hodge_v1.pt')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4575883,
     "sourceId": 7936105,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8935.771486,
   "end_time": "2024-03-25T13:18:46.363449",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-25T10:49:50.591963",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
