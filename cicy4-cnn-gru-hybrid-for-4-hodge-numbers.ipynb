{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "031c9a4f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:27.967228Z",
     "iopub.status.busy": "2024-03-25T13:45:27.966893Z",
     "iopub.status.idle": "2024-03-25T13:45:33.743658Z",
     "shell.execute_reply": "2024-03-25T13:45:33.742837Z"
    },
    "papermill": {
     "duration": 5.787923,
     "end_time": "2024-03-25T13:45:33.745987",
     "exception": false,
     "start_time": "2024-03-25T13:45:27.958064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1a4b679",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:33.763359Z",
     "iopub.status.busy": "2024-03-25T13:45:33.762860Z",
     "iopub.status.idle": "2024-03-25T13:45:47.016157Z",
     "shell.execute_reply": "2024-03-25T13:45:47.015302Z"
    },
    "papermill": {
     "duration": 13.264679,
     "end_time": "2024-03-25T13:45:47.018354",
     "exception": false,
     "start_time": "2024-03-25T13:45:33.753675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((921497, 16, 20), (921497, 4), (921497,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "path = '/kaggle/input/calabi-yau-cicy-4-folds/'\n",
    "\n",
    "conf = np.load('/kaggle/input/calabi-yau-cicy-4-folds/conf.npy')\n",
    "hodge = np.load(os.path.join(path, 'hodge.npy'))\n",
    "direct = np.load(os.path.join(path, 'direct.npy'))\n",
    "conf.shape, hodge.shape, direct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "486abb8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:47.033883Z",
     "iopub.status.busy": "2024-03-25T13:45:47.033564Z",
     "iopub.status.idle": "2024-03-25T13:45:47.038123Z",
     "shell.execute_reply": "2024-03-25T13:45:47.037303Z"
    },
    "papermill": {
     "duration": 0.014556,
     "end_time": "2024-03-25T13:45:47.040024",
     "exception": false,
     "start_time": "2024-03-25T13:45:47.025468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('saved_models'):\n",
    "    os.makedirs('saved_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd7f920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:47.054646Z",
     "iopub.status.busy": "2024-03-25T13:45:47.054384Z",
     "iopub.status.idle": "2024-03-25T13:45:47.164888Z",
     "shell.execute_reply": "2024-03-25T13:45:47.163948Z"
    },
    "papermill": {
     "duration": 0.120392,
     "end_time": "2024-03-25T13:45:47.167181",
     "exception": false,
     "start_time": "2024-03-25T13:45:47.046789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/calabi-yau-cicy-4-folds')\n",
    "from CICY4_functions import data_generator, batch_gd_scheduler,  calc_accuracy_mr, plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a8d942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:47.183067Z",
     "iopub.status.busy": "2024-03-25T13:45:47.182398Z",
     "iopub.status.idle": "2024-03-25T13:45:47.406298Z",
     "shell.execute_reply": "2024-03-25T13:45:47.405503Z"
    },
    "papermill": {
     "duration": 0.23396,
     "end_time": "2024-03-25T13:45:47.408597",
     "exception": false,
     "start_time": "2024-03-25T13:45:47.174637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test(X, y):\n",
    "    X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 101, shuffle = True)\n",
    "    \n",
    "    X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "    #only need reshape if the y dimension is 1\n",
    "    #y_train = torch.from_numpy(y_train.astype(np.float32).reshape(-1, 1))\n",
    "    y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "\n",
    "    X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "    #y_test = torch.from_numpy(y_test.astype(np.float32).reshape(-1, 1))\n",
    "    y_test = torch.from_numpy(y_test.astype(np.float32))                         \n",
    "    \n",
    "    print(f'X_train shape: {X_train.shape}, \\n y_train shape:{y_train.shape},\\\n",
    "                 \\n X_test shape: {X_test.shape}, \\n y_test shape:{y_test.shape}')\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43511d1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:47.424342Z",
     "iopub.status.busy": "2024-03-25T13:45:47.423587Z",
     "iopub.status.idle": "2024-03-25T13:45:48.745124Z",
     "shell.execute_reply": "2024-03-25T13:45:48.743722Z"
    },
    "papermill": {
     "duration": 1.331399,
     "end_time": "2024-03-25T13:45:48.747200",
     "exception": false,
     "start_time": "2024-03-25T13:45:47.415801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([737197, 16, 20]), \n",
      " y_train shape:torch.Size([737197, 4]),                 \n",
      " X_test shape: torch.Size([184300, 16, 20]), \n",
      " y_test shape:torch.Size([184300, 4])\n"
     ]
    }
   ],
   "source": [
    "X = conf\n",
    "y = hodge\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test(X, y)\n",
    "\n",
    "train_gen = lambda: data_generator(X_train, y_train)\n",
    "test_gen = lambda: data_generator(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5666227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:48.762692Z",
     "iopub.status.busy": "2024-03-25T13:45:48.762167Z",
     "iopub.status.idle": "2024-03-25T13:45:48.821199Z",
     "shell.execute_reply": "2024-03-25T13:45:48.820303Z"
    },
    "papermill": {
     "duration": 0.069274,
     "end_time": "2024-03-25T13:45:48.823572",
     "exception": false,
     "start_time": "2024-03-25T13:45:48.754298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd5b1a5",
   "metadata": {
    "papermill": {
     "duration": 0.006843,
     "end_time": "2024-03-25T13:45:48.838527",
     "exception": false,
     "start_time": "2024-03-25T13:45:48.831684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CNN-RNN hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9307e295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:48.853811Z",
     "iopub.status.busy": "2024-03-25T13:45:48.853328Z",
     "iopub.status.idle": "2024-03-25T13:45:48.860205Z",
     "shell.execute_reply": "2024-03-25T13:45:48.859409Z"
    },
    "papermill": {
     "duration": 0.01652,
     "end_time": "2024-03-25T13:45:48.861989",
     "exception": false,
     "start_time": "2024-03-25T13:45:48.845469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################### CNN ###############################\n",
    "class CNN_block(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,128, 4, 1)\n",
    "        #self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.conv2 = nn.Conv2d(128,64, 3, 1)\n",
    "        #self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.mxpool = nn.MaxPool2d(2,2)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.conv_total = nn.Sequential(\n",
    "            self.conv1,\n",
    "            #self.bn1,\n",
    "            self.mxpool,\n",
    "            #self.bn2,\n",
    "            self.conv2,\n",
    "            self.mxpool,\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv_total(x))\n",
    "        #reshape is the same as flat(x)\n",
    "        #x = x.reshape(x.shape[0], -1)\n",
    "        x = self.flat(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce841326",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:48.877010Z",
     "iopub.status.busy": "2024-03-25T13:45:48.876719Z",
     "iopub.status.idle": "2024-03-25T13:45:49.069414Z",
     "shell.execute_reply": "2024-03-25T13:45:49.068495Z"
    },
    "papermill": {
     "duration": 0.202457,
     "end_time": "2024-03-25T13:45:49.071407",
     "exception": false,
     "start_time": "2024-03-25T13:45:48.868950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_block(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (mxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (conv_total): Sequential(\n",
       "    (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_block = CNN_block()\n",
    "cnn_block.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f25a3e29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:49.087225Z",
     "iopub.status.busy": "2024-03-25T13:45:49.086934Z",
     "iopub.status.idle": "2024-03-25T13:45:49.094368Z",
     "shell.execute_reply": "2024-03-25T13:45:49.093539Z"
    },
    "papermill": {
     "duration": 0.017567,
     "end_time": "2024-03-25T13:45:49.096332",
     "exception": false,
     "start_time": "2024-03-25T13:45:49.078765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNN_block(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden, n_rnnlayers, n_outputs):\n",
    "        super(RNN_block,self).__init__()\n",
    "        self.D = n_inputs\n",
    "        self.M = n_hidden\n",
    "        self.K = n_outputs\n",
    "        self.L = n_rnnlayers        \n",
    "        #self.lstm = nn.LSTM(input_size = self.D,\n",
    "        #                   hidden_size = self.M,\n",
    "        #                   num_layers = self.L,\n",
    "        #                   batch_first = True)    \n",
    "        self.gru = nn.GRU(input_size = self.D,\n",
    "                           hidden_size = self.M,\n",
    "                           num_layers = self.L,\n",
    "                           batch_first = True)\n",
    "        #self.fc1 = nn.Linear(self.M, 128)\n",
    "        #self.fc2 = nn.Linear(128, self.K)\n",
    "    def forward(self, X):\n",
    "        #input X is NxTxD\n",
    "        #initial hidden states\n",
    "        h0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
    "        #c0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
    "        #get LSTM unit output:\n",
    "        #output is NxTxM\n",
    "        #out, _ = self.lstm(X, (h0,c0))\n",
    "        out, _ = self.gru(X, h0)   \n",
    "        #we only want h(T) at the final time step\n",
    "        # output is now of shape (N, M)\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceafbcc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:49.112162Z",
     "iopub.status.busy": "2024-03-25T13:45:49.111497Z",
     "iopub.status.idle": "2024-03-25T13:45:49.249235Z",
     "shell.execute_reply": "2024-03-25T13:45:49.248330Z"
    },
    "papermill": {
     "duration": 0.147829,
     "end_time": "2024-03-25T13:45:49.251366",
     "exception": false,
     "start_time": "2024-03-25T13:45:49.103537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_block(\n",
       "  (gru): GRU(20, 100, num_layers=8, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gru_block = RNN_block(20, 64, 6, 4)\n",
    "gru_block = RNN_block(20, 100, 8, 4)\n",
    "gru_block.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86d0931d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:49.267448Z",
     "iopub.status.busy": "2024-03-25T13:45:49.267148Z",
     "iopub.status.idle": "2024-03-25T13:45:49.274322Z",
     "shell.execute_reply": "2024-03-25T13:45:49.273607Z"
    },
    "papermill": {
     "duration": 0.017336,
     "end_time": "2024-03-25T13:45:49.276199",
     "exception": false,
     "start_time": "2024-03-25T13:45:49.258863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN_RNN_hybrid(nn.Module):\n",
    "    def __init__(self, cnn_block, rnn_block, feat_vec_size):\n",
    "        super(CNN_RNN_hybrid, self).__init__()\n",
    "        self.cnn_block = cnn_block\n",
    "        self.rnn_block = rnn_block\n",
    "        self.feat_vec_size = feat_vec_size\n",
    "        self.fc1 = nn.Linear(self.feat_vec_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #output of cnn block is (N,384)\n",
    "        x1 = x.view(-1,1, 16,20)\n",
    "        x1 = self.cnn_block(x1)\n",
    "        #output of rnn block is (N,M = 64)\n",
    "        x2 = self.rnn_block(x)\n",
    "        #concatenate the 2 outputs to produce a feat vec (N, M+384)\n",
    "        xx = torch.cat([x1, x2], dim = 1)\n",
    "        # pass through linear layers\n",
    "        xx = self.fc1(xx)\n",
    "        #final output is 4\n",
    "        xx = self.fc2(xx)\n",
    "        \n",
    "        return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92a9fd23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:49.291838Z",
     "iopub.status.busy": "2024-03-25T13:45:49.291573Z",
     "iopub.status.idle": "2024-03-25T13:45:49.302555Z",
     "shell.execute_reply": "2024-03-25T13:45:49.301747Z"
    },
    "papermill": {
     "duration": 0.02104,
     "end_time": "2024-03-25T13:45:49.304430",
     "exception": false,
     "start_time": "2024-03-25T13:45:49.283390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_RNN_hybrid(\n",
       "  (cnn_block): CNN_block(\n",
       "    (conv1): Conv2d(1, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (mxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "    (conv_total): Sequential(\n",
       "      (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (rnn_block): RNN_block(\n",
       "    (gru): GRU(20, 100, num_layers=8, batch_first=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=484, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN_RNN_hybrid(cnn_block, gru_block, 100+384)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0440a587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:49.320437Z",
     "iopub.status.busy": "2024-03-25T13:45:49.320169Z",
     "iopub.status.idle": "2024-03-25T13:45:49.325025Z",
     "shell.execute_reply": "2024-03-25T13:45:49.324294Z"
    },
    "papermill": {
     "duration": 0.014945,
     "end_time": "2024-03-25T13:45:49.326759",
     "exception": false,
     "start_time": "2024-03-25T13:45:49.311814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787140\n"
     ]
    }
   ],
   "source": [
    "#count the number of parameters in the model\n",
    "params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "print(sum(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e1c538",
   "metadata": {
    "papermill": {
     "duration": 0.007183,
     "end_time": "2024-03-25T13:45:49.341241",
     "exception": false,
     "start_time": "2024-03-25T13:45:49.334058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Shape Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef4ec001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:49.357650Z",
     "iopub.status.busy": "2024-03-25T13:45:49.357030Z",
     "iopub.status.idle": "2024-03-25T13:45:49.471168Z",
     "shell.execute_reply": "2024-03-25T13:45:49.470152Z"
    },
    "papermill": {
     "duration": 0.124762,
     "end_time": "2024-03-25T13:45:49.473372",
     "exception": false,
     "start_time": "2024-03-25T13:45:49.348610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN BLOCK SHAPE TRACING\n",
      "Original shape of the image before passing through the network: \n",
      " torch.Size([16, 20])\n",
      "\n",
      "Reshape the size to take in account the batch number\n",
      "The new size is torch.Size([1, 16, 20])\n",
      "\n",
      "Shape of the image after passing through the GRU(20, 100, num_layers=8, batch_first=True): \n",
      " torch.Size([1, 16, 100])\n",
      "\n",
      "The final output shape is torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "X = X_train[0].to(device)\n",
    "y = y_train[0].to(device)\n",
    "print('RNN BLOCK SHAPE TRACING')\n",
    "print(f'Original shape of the image before passing through the network: \\n {X.shape}\\n')\n",
    "\n",
    "print('Reshape the size to take in account the batch number')\n",
    "X = X.view(1,16,20)\n",
    "print(f'The new size is {X.shape}\\n')\n",
    "\n",
    "h0 = torch.zeros(gru_block.L, X.size(0), gru_block.M).to(device)\n",
    "#c0 = torch.zeros(gru_block.L, X.size(0), gru_block.M).to(device)\n",
    "X, _ = gru_block.gru(X, h0)\n",
    "print(f'Shape of the image after passing through the {gru_block.gru}: \\n {X.shape}\\n')\n",
    "\n",
    "#get only the h(T) at the last time step\n",
    "Xg = X[:, -1, :]\n",
    "print(f'The final output shape is {Xg.shape}')\n",
    "#print(X)\n",
    "#print(f'Target: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9088462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:49.489774Z",
     "iopub.status.busy": "2024-03-25T13:45:49.489499Z",
     "iopub.status.idle": "2024-03-25T13:45:49.935830Z",
     "shell.execute_reply": "2024-03-25T13:45:49.934806Z"
    },
    "papermill": {
     "duration": 0.457371,
     "end_time": "2024-03-25T13:45:49.938431",
     "exception": false,
     "start_time": "2024-03-25T13:45:49.481060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN BLOCK SHAPE TRACING\n",
      "Original shape of the image before passing through the network: \n",
      " torch.Size([16, 20])\n",
      "\n",
      "Reshape the size to take in account the batch number\n",
      "The new size is torch.Size([1, 1, 16, 20])\n",
      "\n",
      "Original shape of the image after passing through Sequential(\n",
      "  (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "): \n",
      " torch.Size([1, 64, 2, 3])\n",
      "\n",
      "Original shape of the image after passing through Flatten(start_dim=1, end_dim=-1): \n",
      " torch.Size([1, 384])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = X_train[0].to(device)\n",
    "print('CNN BLOCK SHAPE TRACING')\n",
    "print(f'Original shape of the image before passing through the network: \\n {X.shape}\\n')\n",
    "\n",
    "print('Reshape the size to take in account the batch number')\n",
    "X = X.view(1,1,16,20)\n",
    "print(f'The new size is {X.shape}\\n')\n",
    "\n",
    "X = cnn_block.conv_total(X)\n",
    "print(f'Original shape of the image after passing through {cnn_block.conv_total}: \\n {X.shape}\\n')\n",
    "\n",
    "#X = X.reshape(X.shape[0], -1)\n",
    "#print(f'After reshaping: {X.shape}') [1,384]\n",
    "Xc = cnn_block.flat(X)\n",
    "print(f'Original shape of the image after passing through {cnn_block.flat}: \\n {Xc.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "809cebb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:49.961826Z",
     "iopub.status.busy": "2024-03-25T13:45:49.961526Z",
     "iopub.status.idle": "2024-03-25T13:45:49.987086Z",
     "shell.execute_reply": "2024-03-25T13:45:49.986089Z"
    },
    "papermill": {
     "duration": 0.039381,
     "end_time": "2024-03-25T13:45:49.989058",
     "exception": false,
     "start_time": "2024-03-25T13:45:49.949677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 100]), torch.Size([1, 384]), torch.Size([1, 484]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat = torch.cat([Xc, Xg], dim=1) \n",
    "Xg.shape, Xc.shape, X_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed17aa24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:50.006396Z",
     "iopub.status.busy": "2024-03-25T13:45:50.006075Z",
     "iopub.status.idle": "2024-03-25T13:45:50.073956Z",
     "shell.execute_reply": "2024-03-25T13:45:50.072913Z"
    },
    "papermill": {
     "duration": 0.079258,
     "end_time": "2024-03-25T13:45:50.076266",
     "exception": false,
     "start_time": "2024-03-25T13:45:49.997008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-RNN HYBRID BLOCK SHAPE TRACING\n",
      "Original shape of the image before passing through the network: \n",
      " torch.Size([16, 20])\n",
      "\n",
      "Reshape the size to take in account the batch number\n",
      "The new size is torch.Size([1, 16, 20])\n",
      "\n",
      "Shape  after passing through the entire network: \n",
      " torch.Size([1, 4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = X_train[0].to(device)\n",
    "print('CNN-RNN HYBRID BLOCK SHAPE TRACING')\n",
    "print(f'Original shape of the image before passing through the network: \\n {X.shape}\\n')\n",
    "\n",
    "print('Reshape the size to take in account the batch number')\n",
    "X = X.view(1,16,20)\n",
    "print(f'The new size is {X.shape}\\n')\n",
    "\n",
    "X = model(X)\n",
    "print(f'Shape  after passing through the entire network: \\n {X.shape}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912ecd6",
   "metadata": {
    "papermill": {
     "duration": 0.007657,
     "end_time": "2024-03-25T13:45:50.092206",
     "exception": false,
     "start_time": "2024-03-25T13:45:50.084549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train loop with scheduler\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html\n",
    "\n",
    "https://residentmario.github.io/pytorch-training-performance-guide/lr-sched-and-optim.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0b62606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:50.111279Z",
     "iopub.status.busy": "2024-03-25T13:45:50.110759Z",
     "iopub.status.idle": "2024-03-25T13:45:52.600623Z",
     "shell.execute_reply": "2024-03-25T13:45:52.599631Z"
    },
    "papermill": {
     "duration": 2.502509,
     "end_time": "2024-03-25T13:45:52.602875",
     "exception": false,
     "start_time": "2024-03-25T13:45:50.100366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_epoch = 200\n",
    "criterion = nn.MSELoss()\n",
    "batch_size = 128\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "#optimizer = torch.optim.SGD(model.parameters())\n",
    "\n",
    "#scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)\n",
    "#scheduler = lr_scheduler.OneCycleLR(optimizer=optimizer, epochs=max_epoch,\n",
    "#            pct_start=0.0, steps_per_epoch=len(X_train)//batch_size,\n",
    "#            max_lr= 0.01, div_factor=25, final_div_factor=4.0e-01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "197ae5dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T13:45:52.621394Z",
     "iopub.status.busy": "2024-03-25T13:45:52.620903Z",
     "iopub.status.idle": "2024-03-25T16:15:33.031984Z",
     "shell.execute_reply": "2024-03-25T16:15:33.031014Z"
    },
    "papermill": {
     "duration": 8980.447403,
     "end_time": "2024-03-25T16:15:33.058980",
     "exception": false,
     "start_time": "2024-03-25T13:45:52.611577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:149: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200, train loss:  685.8872          test_loss:  504.9681, duration: 0:00:45.100572,           learning rate: (0.001, 0.0005050107412538795)\n",
      "Epoch: 2/200, train loss:  450.3318          test_loss:  413.3514, duration: 0:00:44.657776,           learning rate: (0.0005050107412538795, 0.00025245496761324684)\n",
      "Epoch: 3/200, train loss:  354.7666          test_loss:  328.7154, duration: 0:00:44.663661,           learning rate: (0.00025245496761324684, 4.0169584454489425e-05)\n",
      "Epoch: 4/200, train loss:  316.7877          test_loss:  316.3518, duration: 0:00:44.578267,           learning rate: (4.0169584454489425e-05, 0.0007060114411411234)\n",
      "Epoch: 5/200, train loss:  300.4137          test_loss:  272.4715, duration: 0:00:44.568447,           learning rate: (0.0007060114411411234, 0.00014329736426895739)\n",
      "Epoch: 6/200, train loss:  256.7443          test_loss:  262.4693, duration: 0:00:44.634968,           learning rate: (0.00014329736426895739, 0.0008569508003124687)\n",
      "Epoch: 7/200, train loss:  257.9009          test_loss:  254.8246, duration: 0:00:44.555428,           learning rate: (0.0008569508003124687, 0.00047245581400074446)\n",
      "Epoch: 8/200, train loss:  228.6090          test_loss:  222.3612, duration: 0:00:44.587885,           learning rate: (0.00047245581400074446, 0.0008686290715139298)\n",
      "Epoch: 9/200, train loss:  206.0464          test_loss:  182.4570, duration: 0:00:44.642221,           learning rate: (0.0008686290715139298, 0.0008582974859038766)\n",
      "Epoch: 10/200, train loss:  169.7486          test_loss:  160.8646, duration: 0:00:44.633974,           learning rate: (0.0008582974859038766, 0.0009816678577874135)\n",
      "Epoch: 11/200, train loss:  156.2906          test_loss:  153.7861, duration: 0:00:44.536952,           learning rate: (0.0009816678577874135, 0.0003139073592288155)\n",
      "Epoch: 12/200, train loss:  133.3292          test_loss:  131.8384, duration: 0:00:44.645711,           learning rate: (0.0003139073592288155, 8.109839092970384e-05)\n",
      "Epoch: 13/200, train loss:  123.3955          test_loss:  131.4264, duration: 0:00:44.621358,           learning rate: (8.109839092970384e-05, 4.9370533804032555e-05)\n",
      "Epoch: 14/200, train loss:  120.8018          test_loss:  127.9282, duration: 0:00:44.559896,           learning rate: (4.9370533804032555e-05, 0.00010221911203733009)\n",
      "Epoch: 15/200, train loss:  120.6620          test_loss:  125.4523, duration: 0:00:44.474677,           learning rate: (0.00010221911203733009, 0.0004291839955339598)\n",
      "Epoch: 16/200, train loss:  125.1439          test_loss:  130.9858, duration: 0:00:44.486217,           learning rate: (0.0004291839955339598, 2.37893259491897e-05)\n",
      "Epoch: 17/200, train loss:  112.3310          test_loss:  120.6410, duration: 0:00:44.524494,           learning rate: (2.37893259491897e-05, 0.000989896257282756)\n",
      "Epoch: 18/200, train loss:  130.7087          test_loss:  130.8687, duration: 0:00:44.680796,           learning rate: (0.000989896257282756, 1.8506316504946497e-05)\n",
      "Epoch: 19/200, train loss:  107.5047          test_loss:  113.4451, duration: 0:00:44.579366,           learning rate: (1.8506316504946497e-05, 0.00026535431151465563)\n",
      "Epoch: 20/200, train loss:  107.4974          test_loss:  112.1092, duration: 0:00:44.489681,           learning rate: (0.00026535431151465563, 0.00010580818898184257)\n",
      "Epoch: 21/200, train loss:  100.4647          test_loss:  109.5125, duration: 0:00:44.654408,           learning rate: (0.00010580818898184257, 5.8529087326713585e-06)\n",
      "Epoch: 22/200, train loss:  97.0256          test_loss:  106.8335, duration: 0:00:44.733659,           learning rate: (5.8529087326713585e-06, 0.00022765965642791258)\n",
      "Epoch: 23/200, train loss:  101.4776          test_loss:  106.7951, duration: 0:00:44.455677,           learning rate: (0.00022765965642791258, 0.00023273860489635506)\n",
      "Epoch: 24/200, train loss:  99.3944          test_loss:  113.3806, duration: 0:00:44.661414,           learning rate: (0.00023273860489635506, 0.00025645323096446594)\n",
      "Epoch: 25/200, train loss:  98.2183          test_loss:  105.6798, duration: 0:00:44.607270,           learning rate: (0.00025645323096446594, 0.0003940310259960918)\n",
      "Epoch: 26/200, train loss:  99.5114          test_loss:  107.3819, duration: 0:00:44.667932,           learning rate: (0.0003940310259960918, 0.00015980258997113468)\n",
      "Epoch: 27/200, train loss:  91.9381          test_loss:  100.7034, duration: 0:00:44.674955,           learning rate: (0.00015980258997113468, 0.0009878417609771627)\n",
      "Epoch: 28/200, train loss:  111.5614          test_loss:  112.7589, duration: 0:00:44.512860,           learning rate: (0.0009878417609771627, 0.00017634512189239267)\n",
      "Epoch: 29/200, train loss:  90.9770          test_loss:  98.2012, duration: 0:00:44.681478,           learning rate: (0.00017634512189239267, 0.0009222637165340495)\n",
      "Epoch: 30/200, train loss:  105.4390          test_loss:  106.5373, duration: 0:00:44.701591,           learning rate: (0.0009222637165340495, 0.0002677938857860226)\n",
      "Epoch: 31/200, train loss:  88.2442          test_loss:  95.1078, duration: 0:00:44.571143,           learning rate: (0.0002677938857860226, 0.0005169312036033879)\n",
      "Epoch: 32/200, train loss:  91.3735          test_loss:  104.0326, duration: 0:00:44.582096,           learning rate: (0.0005169312036033879, 0.0006496354005046984)\n",
      "Epoch: 33/200, train loss:  92.4978          test_loss:  98.1333, duration: 0:00:44.618989,           learning rate: (0.0006496354005046984, 0.0009164593920156936)\n",
      "Epoch: 34/200, train loss:  97.4789          test_loss:  115.9528, duration: 0:00:44.567916,           learning rate: (0.0009164593920156936, 0.0006474478086696636)\n",
      "Epoch: 35/200, train loss:  88.8726          test_loss:  94.0935, duration: 0:00:44.450729,           learning rate: (0.0006474478086696636, 0.00035952365081549703)\n",
      "Epoch: 36/200, train loss:  80.2353          test_loss:  89.0436, duration: 0:00:44.554162,           learning rate: (0.00035952365081549703, 2.240112222313878e-05)\n",
      "Epoch: 37/200, train loss:  72.1109          test_loss:  84.0571, duration: 0:00:44.444853,           learning rate: (2.240112222313878e-05, 0.0006459523691883944)\n",
      "Epoch: 38/200, train loss:  85.7464          test_loss:  90.0758, duration: 0:00:44.966088,           learning rate: (0.0006459523691883944, 1.4191203122138062e-07)\n",
      "Epoch: 39/200, train loss:  77.1710          test_loss:  88.5575, duration: 0:00:44.611055,           learning rate: (1.4191203122138062e-07, 5.047104568099198e-05)\n",
      "Epoch: 40/200, train loss:  71.6765          test_loss:  82.8011, duration: 0:00:44.575662,           learning rate: (5.047104568099198e-05, 0.0008185831170683844)\n",
      "Epoch: 41/200, train loss:  88.2537          test_loss:  96.9181, duration: 0:00:44.442816,           learning rate: (0.0008185831170683844, 0.0007833859922881584)\n",
      "Epoch: 42/200, train loss:  86.2925          test_loss:  97.0766, duration: 0:00:44.527797,           learning rate: (0.0007833859922881584, 0.0008035466080664697)\n",
      "Epoch: 43/200, train loss:  84.9706          test_loss:  89.8917, duration: 0:00:44.472410,           learning rate: (0.0008035466080664697, 2.8934702140942515e-07)\n",
      "Epoch: 44/200, train loss:  75.9934          test_loss:  87.1946, duration: 0:00:44.716316,           learning rate: (2.8934702140942515e-07, 0.00018193730289268152)\n",
      "Epoch: 45/200, train loss:  70.7486          test_loss:  80.7549, duration: 0:00:44.724944,           learning rate: (0.00018193730289268152, 0.000986004592524357)\n",
      "Epoch: 46/200, train loss:  88.2582          test_loss:  93.9514, duration: 0:00:44.630594,           learning rate: (0.000986004592524357, 0.00033824649768639855)\n",
      "Epoch: 47/200, train loss:  72.7973          test_loss:  85.8650, duration: 0:00:44.465310,           learning rate: (0.00033824649768639855, 0.00036579137532294186)\n",
      "Epoch: 48/200, train loss:  71.2923          test_loss:  81.6773, duration: 0:00:44.477338,           learning rate: (0.00036579137532294186, 0.0009321748256392496)\n",
      "Epoch: 49/200, train loss:  83.7903          test_loss:  92.3537, duration: 0:00:44.433545,           learning rate: (0.0009321748256392496, 0.00013057132489337247)\n",
      "Epoch: 50/200, train loss:  67.2174          test_loss:  78.8218, duration: 0:00:44.542731,           learning rate: (0.00013057132489337247, 0.0009661364941879763)\n",
      "Epoch: 51/200, train loss:  84.0646          test_loss:  91.2232, duration: 0:00:44.490496,           learning rate: (0.0009661364941879763, 3.646414464577452e-05)\n",
      "Epoch: 52/200, train loss:  66.6733          test_loss:  77.1768, duration: 0:00:44.433513,           learning rate: (3.646414464577452e-05, 0.0008158960790362379)\n",
      "Epoch: 53/200, train loss:  79.9862          test_loss:  99.7032, duration: 0:00:44.507068,           learning rate: (0.0008158960790362379, 0.0009978285164928236)\n",
      "Epoch: 54/200, train loss:  83.0501          test_loss:  89.0092, duration: 0:00:44.557371,           learning rate: (0.0009978285164928236, 2.4028361788437368e-05)\n",
      "Epoch: 55/200, train loss:  67.3354          test_loss:  77.7269, duration: 0:00:44.488172,           learning rate: (2.4028361788437368e-05, 0.0008778376700613433)\n",
      "Epoch: 56/200, train loss:  80.0428          test_loss:  97.7621, duration: 0:00:44.432038,           learning rate: (0.0008778376700613433, 0.0008814362654271202)\n",
      "Epoch: 57/200, train loss:  78.2398          test_loss:  89.0416, duration: 0:00:44.521856,           learning rate: (0.0008814362654271202, 2.2491386508491362e-05)\n",
      "Epoch: 58/200, train loss:  64.2974          test_loss:  75.1494, duration: 0:00:44.625157,           learning rate: (2.2491386508491362e-05, 0.000523462642614912)\n",
      "Epoch: 59/200, train loss:  69.9694          test_loss:  78.0051, duration: 0:00:44.367658,           learning rate: (0.000523462642614912, 0.0009049789895897665)\n",
      "Epoch: 60/200, train loss:  77.2998          test_loss:  88.4224, duration: 0:00:44.587104,           learning rate: (0.0009049789895897665, 6.01632627227155e-05)\n",
      "Epoch: 61/200, train loss:  62.1341          test_loss:  74.0642, duration: 0:00:44.559999,           learning rate: (6.01632627227155e-05, 0.0003551095683927342)\n",
      "Epoch: 62/200, train loss:  64.7543          test_loss:  75.2541, duration: 0:00:44.637685,           learning rate: (0.0003551095683927342, 0.0005398738264497757)\n",
      "Epoch: 63/200, train loss:  67.7576          test_loss:  81.0395, duration: 0:00:44.526617,           learning rate: (0.0005398738264497757, 0.0009735756273304111)\n",
      "Epoch: 64/200, train loss:  77.6217          test_loss:  89.8434, duration: 0:00:44.545948,           learning rate: (0.0009735756273304111, 6.04858315338408e-07)\n",
      "Epoch: 65/200, train loss:  69.3272          test_loss:  80.3328, duration: 0:00:44.560934,           learning rate: (6.04858315338408e-07, 0.0009972694349724119)\n",
      "Epoch: 66/200, train loss:  78.9923          test_loss:  85.2073, duration: 0:00:44.623472,           learning rate: (0.0009972694349724119, 0.00046746414794821315)\n",
      "Epoch: 67/200, train loss:  65.8510          test_loss:  75.6855, duration: 0:00:44.477550,           learning rate: (0.00046746414794821315, 0.0006068473985691375)\n",
      "Epoch: 68/200, train loss:  67.1903          test_loss:  78.4953, duration: 0:00:44.494542,           learning rate: (0.0006068473985691375, 0.0009451646875868439)\n",
      "Epoch: 69/200, train loss:  75.0283          test_loss:  83.9293, duration: 0:00:44.484864,           learning rate: (0.0009451646875868439, 0.0006650380073948708)\n",
      "Epoch: 70/200, train loss:  68.3856          test_loss:  77.3490, duration: 0:00:44.699164,           learning rate: (0.0006650380073948708, 0.0008363951225640714)\n",
      "Epoch: 71/200, train loss:  71.7269          test_loss:  83.7818, duration: 0:00:44.673228,           learning rate: (0.0008363951225640714, 0.0006867182896192677)\n",
      "Epoch: 72/200, train loss:  68.2471          test_loss:  79.4040, duration: 0:00:44.613396,           learning rate: (0.0006867182896192677, 0.000991259847226163)\n",
      "Epoch: 73/200, train loss:  74.5731          test_loss:  85.5762, duration: 0:00:44.623545,           learning rate: (0.000991259847226163, 0.00040998497918241306)\n",
      "Epoch: 74/200, train loss:  62.0772          test_loss:  71.6263, duration: 0:00:44.708312,           learning rate: (0.00040998497918241306, 6.385341626837749e-05)\n",
      "Epoch: 75/200, train loss:  54.3548          test_loss:  68.4704, duration: 0:00:44.564066,           learning rate: (6.385341626837749e-05, 5.6629425260545375e-05)\n",
      "Epoch: 76/200, train loss:  53.2831          test_loss:  68.1787, duration: 0:00:44.445377,           learning rate: (5.6629425260545375e-05, 7.963903003380335e-05)\n",
      "Epoch: 77/200, train loss:  53.3707          test_loss:  68.1470, duration: 0:00:44.541338,           learning rate: (7.963903003380335e-05, 8.235175232029535e-05)\n",
      "Epoch: 78/200, train loss:  53.1145          test_loss:  68.3951, duration: 0:00:44.527331,           learning rate: (8.235175232029535e-05, 6.221555788909495e-05)\n",
      "Epoch: 79/200, train loss:  52.2995          test_loss:  67.9260, duration: 0:00:44.455999,           learning rate: (6.221555788909495e-05, 0.00010242925411844394)\n",
      "Epoch: 80/200, train loss:  52.9261          test_loss:  69.2763, duration: 0:00:44.450618,           learning rate: (0.00010242925411844394, 1.2868328508877647e-05)\n",
      "Epoch: 81/200, train loss:  50.9695          test_loss:  67.1479, duration: 0:00:44.683602,           learning rate: (1.2868328508877647e-05, 0.0001876357623801026)\n",
      "Epoch: 82/200, train loss:  54.4524          test_loss:  68.9229, duration: 0:00:44.797415,           learning rate: (0.0001876357623801026, 2.8352277747588694e-05)\n",
      "Epoch: 83/200, train loss:  51.0603          test_loss:  67.0576, duration: 0:00:44.480577,           learning rate: (2.8352277747588694e-05, 0.0001988393875672655)\n",
      "Epoch: 84/200, train loss:  54.3790          test_loss:  69.0486, duration: 0:00:44.678839,           learning rate: (0.0001988393875672655, 2.2166949898892563e-05)\n",
      "Epoch: 85/200, train loss:  50.6155          test_loss:  66.7399, duration: 0:00:44.627330,           learning rate: (2.2166949898892563e-05, 0.00024011035020210525)\n",
      "Epoch: 86/200, train loss:  55.0978          test_loss:  70.1225, duration: 0:00:44.742060,           learning rate: (0.00024011035020210525, 3.70276040432771e-07)\n",
      "Epoch: 87/200, train loss:  51.9126          test_loss:  68.1966, duration: 0:00:44.490598,           learning rate: (3.70276040432771e-07, 7.812373098870613e-05)\n",
      "Epoch: 88/200, train loss:  51.3315          test_loss:  67.2747, duration: 0:00:44.518413,           learning rate: (7.812373098870613e-05, 0.0001723401968206007)\n",
      "Epoch: 89/200, train loss:  53.0322          test_loss:  68.1555, duration: 0:00:44.519099,           learning rate: (0.0001723401968206007, 8.162133551213397e-05)\n",
      "Epoch: 90/200, train loss:  50.8374          test_loss:  66.9889, duration: 0:00:44.676027,           learning rate: (8.162133551213397e-05, 0.00020752493963339803)\n",
      "Epoch: 91/200, train loss:  53.4557          test_loss:  69.3337, duration: 0:00:44.617326,           learning rate: (0.00020752493963339803, 1.0914099535552392e-05)\n",
      "Epoch: 92/200, train loss:  49.5298          test_loss:  66.2295, duration: 0:00:44.446008,           learning rate: (1.0914099535552392e-05, 0.00031163679342782725)\n",
      "Epoch: 93/200, train loss:  55.8958          test_loss:  69.8704, duration: 0:00:44.509741,           learning rate: (0.00031163679342782725, 4.142610733195995e-07)\n",
      "Epoch: 94/200, train loss:  52.3743          test_loss:  68.3234, duration: 0:00:44.736075,           learning rate: (4.142610733195995e-07, 6.777196027339682e-05)\n",
      "Epoch: 95/200, train loss:  50.4677          test_loss:  66.3921, duration: 0:00:44.488836,           learning rate: (6.777196027339682e-05, 0.00028823445666780113)\n",
      "Epoch: 96/200, train loss:  55.0154          test_loss:  70.1335, duration: 0:00:44.555781,           learning rate: (0.00028823445666780113, 4.398715844832202e-07)\n",
      "Epoch: 97/200, train loss:  51.7641          test_loss:  67.9830, duration: 0:00:44.498780,           learning rate: (4.398715844832202e-07, 9.7062719667459e-05)\n",
      "Epoch: 98/200, train loss:  50.6364          test_loss:  66.9295, duration: 0:00:44.709521,           learning rate: (9.7062719667459e-05, 0.00021513163519543965)\n",
      "Epoch: 99/200, train loss:  52.9348          test_loss:  69.0582, duration: 0:00:44.596847,           learning rate: (0.00021513163519543965, 2.17284649708398e-05)\n",
      "Epoch: 100/200, train loss:  48.7948          test_loss:  65.7906, duration: 0:00:44.450160,           learning rate: (2.17284649708398e-05, 0.00037707929499884523)\n",
      "Epoch: 101/200, train loss:  57.0709          test_loss:  75.9169, duration: 0:00:44.542864,           learning rate: (0.00037707929499884523, 0.0006420484878846812)\n",
      "Epoch: 102/200, train loss:  64.1530          test_loss:  76.0604, duration: 0:00:44.622874,           learning rate: (0.0006420484878846812, 0.0006635064657494583)\n",
      "Epoch: 103/200, train loss:  65.0913          test_loss:  78.3542, duration: 0:00:44.474200,           learning rate: (0.0006635064657494583, 0.0009346446845002304)\n",
      "Epoch: 104/200, train loss:  72.3294          test_loss:  79.7385, duration: 0:00:44.539916,           learning rate: (0.0009346446845002304, 0.0009983134576727912)\n",
      "Epoch: 105/200, train loss:  74.1035          test_loss:  84.8097, duration: 0:00:44.615879,           learning rate: (0.0009983134576727912, 0.0005298821982526126)\n",
      "Epoch: 106/200, train loss:  62.9415          test_loss:  73.7127, duration: 0:00:44.734378,           learning rate: (0.0005298821982526126, 0.00030326049131952176)\n",
      "Epoch: 107/200, train loss:  56.4802          test_loss:  69.5302, duration: 0:00:44.630789,           learning rate: (0.00030326049131952176, 5.435807992143937e-06)\n",
      "Epoch: 108/200, train loss:  50.6866          test_loss:  66.3551, duration: 0:00:44.602016,           learning rate: (5.435807992143937e-06, 0.0002935175301740667)\n",
      "Epoch: 109/200, train loss:  55.4235          test_loss:  69.3191, duration: 0:00:44.848483,           learning rate: (0.0002935175301740667, 1.1394899610414123e-05)\n",
      "Epoch: 110/200, train loss:  49.9081          test_loss:  65.8265, duration: 0:00:44.824754,           learning rate: (1.1394899610414123e-05, 0.00037162041973769444)\n",
      "Epoch: 111/200, train loss:  56.8562          test_loss:  70.2014, duration: 0:00:44.546320,           learning rate: (0.00037162041973769444, 1.000816507370661e-06)\n",
      "Epoch: 112/200, train loss:  52.3394          test_loss:  67.6185, duration: 0:00:44.509723,           learning rate: (1.000816507370661e-06, 0.00013353609453985215)\n",
      "Epoch: 113/200, train loss:  51.1557          test_loss:  66.3272, duration: 0:00:44.589970,           learning rate: (0.00013353609453985215, 0.00029751828729233676)\n",
      "Epoch: 114/200, train loss:  54.3319          test_loss:  68.0115, duration: 0:00:44.587593,           learning rate: (0.00029751828729233676, 9.443397249352125e-05)\n",
      "Epoch: 115/200, train loss:  49.5792          test_loss:  66.1462, duration: 0:00:44.494159,           learning rate: (9.443397249352125e-05, 0.00032382035158916056)\n",
      "Epoch: 116/200, train loss:  54.5305          test_loss:  68.1500, duration: 0:00:44.505236,           learning rate: (0.00032382035158916056, 8.20968345976853e-05)\n",
      "Epoch: 117/200, train loss:  49.0085          test_loss:  65.3017, duration: 0:00:44.627725,           learning rate: (8.20968345976853e-05, 0.00045267722225194484)\n",
      "Epoch: 118/200, train loss:  57.7962          test_loss:  74.2873, duration: 0:00:44.655071,           learning rate: (0.00045267722225194484, 0.0003889828494477551)\n",
      "Epoch: 119/200, train loss:  56.0560          test_loss:  69.7922, duration: 0:00:44.711939,           learning rate: (0.0003889828494477551, 1.0647816147325018e-06)\n",
      "Epoch: 120/200, train loss:  50.8454          test_loss:  66.6010, duration: 0:00:44.653106,           learning rate: (1.0647816147325018e-06, 0.00025898532125999245)\n",
      "Epoch: 121/200, train loss:  52.7329          test_loss:  68.1130, duration: 0:00:44.632966,           learning rate: (0.00025898532125999245, 8.53145181688873e-05)\n",
      "Epoch: 122/200, train loss:  48.2518          test_loss:  64.8974, duration: 0:00:44.864983,           learning rate: (8.53145181688873e-05, 0.0005161080008640052)\n",
      "Epoch: 123/200, train loss:  59.2913          test_loss:  77.6983, duration: 0:00:44.819210,           learning rate: (0.0005161080008640052, 0.0008748809837619888)\n",
      "Epoch: 124/200, train loss:  69.9004          test_loss:  78.0244, duration: 0:00:45.139465,           learning rate: (0.0008748809837619888, 0.0009067535215272638)\n",
      "Epoch: 125/200, train loss:  70.8650          test_loss:  80.4825, duration: 0:00:45.305377,           learning rate: (0.0009067535215272638, 0.0009942667351212288)\n",
      "Epoch: 126/200, train loss:  73.4730          test_loss:  88.2391, duration: 0:00:45.126533,           learning rate: (0.0009942667351212288, 7.45778685392579e-05)\n",
      "Epoch: 127/200, train loss:  55.2075          test_loss:  66.6664, duration: 0:00:45.064209,           learning rate: (7.45778685392579e-05, 0.00025004035512320475)\n",
      "Epoch: 128/200, train loss:  54.9725          test_loss:  68.4551, duration: 0:00:44.917201,           learning rate: (0.00025004035512320475, 5.7744737071305786e-05)\n",
      "Epoch: 129/200, train loss:  49.8432          test_loss:  65.1454, duration: 0:00:45.230283,           learning rate: (5.7744737071305786e-05, 0.00047717381728634164)\n",
      "Epoch: 130/200, train loss:  58.6005          test_loss:  72.7888, duration: 0:00:45.233944,           learning rate: (0.00047717381728634164, 0.000179928930461857)\n",
      "Epoch: 131/200, train loss:  51.5387          test_loss:  66.6518, duration: 0:00:45.527596,           learning rate: (0.000179928930461857, 0.0002520307060383668)\n",
      "Epoch: 132/200, train loss:  52.3466          test_loss:  66.9838, duration: 0:00:45.667320,           learning rate: (0.0002520307060383668, 0.0002081675322045931)\n",
      "Epoch: 133/200, train loss:  50.9640          test_loss:  65.0150, duration: 0:00:45.595747,           learning rate: (0.0002081675322045931, 0.0004976366719699877)\n",
      "Epoch: 134/200, train loss:  58.2476          test_loss:  70.6997, duration: 0:00:45.869596,           learning rate: (0.0004976366719699877, 1.2030338172208721e-05)\n",
      "Epoch: 135/200, train loss:  49.2253          test_loss:  64.3418, duration: 0:00:45.474349,           learning rate: (1.2030338172208721e-05, 0.0006026527055905201)\n",
      "Epoch: 136/200, train loss:  61.5716          test_loss:  71.4672, duration: 0:00:45.372367,           learning rate: (0.0006026527055905201, 5.21826254855754e-05)\n",
      "Epoch: 137/200, train loss:  49.5132          test_loss:  64.3802, duration: 0:00:45.232239,           learning rate: (5.21826254855754e-05, 0.0005967512855240495)\n",
      "Epoch: 138/200, train loss:  61.2925          test_loss:  74.9839, duration: 0:00:45.613153,           learning rate: (0.0005967512855240495, 0.0004974738210846668)\n",
      "Epoch: 139/200, train loss:  58.0835          test_loss:  69.3390, duration: 0:00:45.451104,           learning rate: (0.0004974738210846668, 1.0740588349454517e-05)\n",
      "Epoch: 140/200, train loss:  49.2075          test_loss:  64.5575, duration: 0:00:45.292341,           learning rate: (1.0740588349454517e-05, 0.0005692898711947559)\n",
      "Epoch: 141/200, train loss:  60.5004          test_loss:  73.5300, duration: 0:00:45.666200,           learning rate: (0.0005692898711947559, 0.0002772114983687614)\n",
      "Epoch: 142/200, train loss:  52.6164          test_loss:  68.3033, duration: 0:00:45.746843,           learning rate: (0.0002772114983687614, 6.93659023950362e-05)\n",
      "Epoch: 143/200, train loss:  47.3159          test_loss:  64.3919, duration: 0:00:45.509843,           learning rate: (6.93659023950362e-05, 0.0005949396879382749)\n",
      "Epoch: 144/200, train loss:  60.4551          test_loss:  71.9486, duration: 0:00:45.502248,           learning rate: (0.0005949396879382749, 9.079945949281098e-05)\n",
      "Epoch: 145/200, train loss:  48.8850          test_loss:  63.6969, duration: 0:00:45.653791,           learning rate: (9.079945949281098e-05, 0.0006990140601857858)\n",
      "Epoch: 146/200, train loss:  63.6734          test_loss:  81.9518, duration: 0:00:45.528529,           learning rate: (0.0006990140601857858, 0.0009089166462100981)\n",
      "Epoch: 147/200, train loss:  69.1353          test_loss:  80.2356, duration: 0:00:45.491813,           learning rate: (0.0009089166462100981, 0.0009986304753833231)\n",
      "Epoch: 148/200, train loss:  71.2417          test_loss:  79.0682, duration: 0:00:45.728448,           learning rate: (0.0009986304753833231, 0.00097873059074237)\n",
      "Epoch: 149/200, train loss:  71.0873          test_loss:  82.4465, duration: 0:00:45.671133,           learning rate: (0.00097873059074237, 0.0008594424409867737)\n",
      "Epoch: 150/200, train loss:  67.2567          test_loss:  77.4807, duration: 0:00:45.844015,           learning rate: (0.0008594424409867737, 0.0008514021766546899)\n",
      "Epoch: 151/200, train loss:  66.3965          test_loss:  91.3059, duration: 0:00:45.498251,           learning rate: (0.0008514021766546899, 4.149084972255052e-05)\n",
      "Epoch: 152/200, train loss:  52.2250          test_loss:  64.9531, duration: 0:00:45.729140,           learning rate: (4.149084972255052e-05, 0.0005073599495986117)\n",
      "Epoch: 153/200, train loss:  58.1936          test_loss:  69.3287, duration: 0:00:45.676307,           learning rate: (0.0005073599495986117, 1.1079057470262444e-05)\n",
      "Epoch: 154/200, train loss:  49.7319          test_loss:  64.2078, duration: 0:00:46.161019,           learning rate: (1.1079057470262444e-05, 0.0006231608813783053)\n",
      "Epoch: 155/200, train loss:  60.4148          test_loss:  76.0373, duration: 0:00:45.214572,           learning rate: (0.0006231608813783053, 0.0006600700764845342)\n",
      "Epoch: 156/200, train loss:  60.6769          test_loss:  73.1257, duration: 0:00:45.446034,           learning rate: (0.0006600700764845342, 0.00022230954340418302)\n",
      "Epoch: 157/200, train loss:  51.0591          test_loss:  65.7716, duration: 0:00:45.642843,           learning rate: (0.00022230954340418302, 0.00037997539765983145)\n",
      "Epoch: 158/200, train loss:  53.4390          test_loss:  66.9566, duration: 0:00:45.685414,           learning rate: (0.00037997539765983145, 0.00021164371067489718)\n",
      "Epoch: 159/200, train loss:  49.4061          test_loss:  63.6834, duration: 0:00:45.671052,           learning rate: (0.00021164371067489718, 0.0007009585082492038)\n",
      "Epoch: 160/200, train loss:  61.1213          test_loss:  71.1021, duration: 0:00:45.523363,           learning rate: (0.0007009585082492038, 2.966927680280329e-05)\n",
      "Epoch: 161/200, train loss:  49.0842          test_loss:  63.1968, duration: 0:00:45.542443,           learning rate: (2.966927680280329e-05, 0.0007683408961871308)\n",
      "Epoch: 162/200, train loss:  63.6747          test_loss:  78.8976, duration: 0:00:45.317119,           learning rate: (0.0007683408961871308, 0.0009703113020431835)\n",
      "Epoch: 163/200, train loss:  67.9704          test_loss:  77.9133, duration: 0:00:45.378267,           learning rate: (0.0009703113020431835, 0.0008963564192628407)\n",
      "Epoch: 164/200, train loss:  66.6674          test_loss:  75.5870, duration: 0:00:45.223473,           learning rate: (0.0008963564192628407, 0.000591688883154878)\n",
      "Epoch: 165/200, train loss:  58.8645          test_loss:  70.4842, duration: 0:00:45.207523,           learning rate: (0.000591688883154878, 5.772946123406064e-06)\n",
      "Epoch: 166/200, train loss:  50.2468          test_loss:  64.0478, duration: 0:00:45.280715,           learning rate: (5.772946123406064e-06, 0.0006473478263763007)\n",
      "Epoch: 167/200, train loss:  59.9365          test_loss:  72.1337, duration: 0:00:45.159230,           learning rate: (0.0006473478263763007, 0.00010818602817746947)\n",
      "Epoch: 168/200, train loss:  48.7418          test_loss:  63.3740, duration: 0:00:45.295800,           learning rate: (0.00010818602817746947, 0.0007444490998873107)\n",
      "Epoch: 169/200, train loss:  62.0136          test_loss:  76.7873, duration: 0:00:45.152793,           learning rate: (0.0007444490998873107, 0.0007662230024809422)\n",
      "Epoch: 170/200, train loss:  62.1120          test_loss:  72.9589, duration: 0:00:45.312642,           learning rate: (0.0007662230024809422, 0.00020090818154289752)\n",
      "Epoch: 171/200, train loss:  50.3636          test_loss:  63.1943, duration: 0:00:45.171220,           learning rate: (0.00020090818154289752, 0.0007686649196297315)\n",
      "Epoch: 172/200, train loss:  62.4602          test_loss:  72.3282, duration: 0:00:45.374373,           learning rate: (0.0007686649196297315, 0.00012788552079645932)\n",
      "Epoch: 173/200, train loss:  49.1029          test_loss:  62.4518, duration: 0:00:45.524547,           learning rate: (0.00012788552079645932, 0.0008588673626551449)\n",
      "Epoch: 174/200, train loss:  64.6951          test_loss:  72.4594, duration: 0:00:45.840832,           learning rate: (0.0008588673626551449, 0.0001419650666673998)\n",
      "Epoch: 175/200, train loss:  49.6971          test_loss:  62.4924, duration: 0:00:45.651567,           learning rate: (0.0001419650666673998, 0.0008543973137545773)\n",
      "Epoch: 176/200, train loss:  64.1775          test_loss:  71.4749, duration: 0:00:45.558865,           learning rate: (0.0008543973137545773, 5.272078469719904e-05)\n",
      "Epoch: 177/200, train loss:  49.2729          test_loss:  62.6668, duration: 0:00:45.400310,           learning rate: (5.272078469719904e-05, 0.0008345478187466391)\n",
      "Epoch: 178/200, train loss:  63.6084          test_loss:  77.6463, duration: 0:00:45.346596,           learning rate: (0.0008345478187466391, 0.0008694189254516389)\n",
      "Epoch: 179/200, train loss:  64.1200          test_loss:  72.8958, duration: 0:00:45.274124,           learning rate: (0.0008694189254516389, 0.00019302263994501906)\n",
      "Epoch: 180/200, train loss:  50.2383          test_loss:  65.5886, duration: 0:00:45.134395,           learning rate: (0.00019302263994501906, 0.00040806482988702073)\n",
      "Epoch: 181/200, train loss:  52.9944          test_loss:  65.4372, duration: 0:00:45.487669,           learning rate: (0.00040806482988702073, 0.00043154806278951276)\n",
      "Epoch: 182/200, train loss:  52.7362          test_loss:  74.3359, duration: 0:00:45.701395,           learning rate: (0.00043154806278951276, 0.00039643918259719285)\n",
      "Epoch: 183/200, train loss:  51.5948          test_loss:  65.9610, duration: 0:00:45.235824,           learning rate: (0.00039643918259719285, 0.00035132251794612246)\n",
      "Epoch: 184/200, train loss:  50.5153          test_loss:  63.2558, duration: 0:00:45.209634,           learning rate: (0.00035132251794612246, 0.0007604665766556985)\n",
      "Epoch: 185/200, train loss:  60.5270          test_loss:  68.8360, duration: 0:00:45.062959,           learning rate: (0.0007604665766556985, 3.305930180111788e-05)\n",
      "Epoch: 186/200, train loss:  47.5525          test_loss:  61.5231, duration: 0:00:45.396057,           learning rate: (3.305930180111788e-05, 0.0009438428385578191)\n",
      "Epoch: 187/200, train loss:  65.5502          test_loss:  77.9320, duration: 0:00:44.999023,           learning rate: (0.0009438428385578191, 0.0008981403797454615)\n",
      "Epoch: 188/200, train loss:  64.6294          test_loss:  75.8633, duration: 0:00:45.084962,           learning rate: (0.0008981403797454615, 0.0006339490603530607)\n",
      "Epoch: 189/200, train loss:  57.8958          test_loss:  67.8129, duration: 0:00:45.066504,           learning rate: (0.0006339490603530607, 0.0001134590244045412)\n",
      "Epoch: 190/200, train loss:  47.3758          test_loss:  61.6949, duration: 0:00:45.079318,           learning rate: (0.0001134590244045412, 0.0009307769767244742)\n",
      "Epoch: 191/200, train loss:  65.3308          test_loss:  94.4640, duration: 0:00:45.094659,           learning rate: (0.0009307769767244742, 0.00041619930118736733)\n",
      "Epoch: 192/200, train loss:  53.3735          test_loss:  67.1481, duration: 0:00:45.253323,           learning rate: (0.00041619930118736733, 0.00018760759456368508)\n",
      "Epoch: 193/200, train loss:  47.6131          test_loss:  61.8823, duration: 0:00:45.413985,           learning rate: (0.00018760759456368508, 0.0009150946614313929)\n",
      "Epoch: 194/200, train loss:  64.4127          test_loss:  73.5503, duration: 0:00:45.249696,           learning rate: (0.0009150946614313929, 0.0002800738099838679)\n",
      "Epoch: 195/200, train loss:  50.5568          test_loss:  62.5258, duration: 0:00:45.250454,           learning rate: (0.0002800738099838679, 0.0008506762566303174)\n",
      "Epoch: 196/200, train loss:  62.4404          test_loss:  71.4122, duration: 0:00:45.386791,           learning rate: (0.0008506762566303174, 4.840535279675379e-05)\n",
      "Epoch: 197/200, train loss:  48.2135          test_loss:  61.6927, duration: 0:00:45.241519,           learning rate: (4.840535279675379e-05, 0.000930956119251652)\n",
      "Epoch: 198/200, train loss:  64.8931          test_loss:  72.9634, duration: 0:00:45.218612,           learning rate: (0.000930956119251652, 0.00020147391877033688)\n",
      "Epoch: 199/200, train loss:  49.3851          test_loss:  63.0790, duration: 0:00:45.167363,           learning rate: (0.00020147391877033688, 0.000783765815833362)\n",
      "Epoch: 200/200, train loss:  60.2095          test_loss:  71.5312, duration: 0:00:45.298601,           learning rate: (0.000783765815833362, 5.6741957331583436e-05)\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses=batch_gd_scheduler(model, criterion, optimizer, train_gen, test_gen, scheduler, \n",
    "                                             max_epoch, device,  cnn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28ec8395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T16:15:33.113094Z",
     "iopub.status.busy": "2024-03-25T16:15:33.112145Z",
     "iopub.status.idle": "2024-03-25T16:15:55.375183Z",
     "shell.execute_reply": "2024-03-25T16:15:55.374082Z"
    },
    "papermill": {
     "duration": 22.291853,
     "end_time": "2024-03-25T16:15:55.377721",
     "exception": false,
     "start_time": "2024-03-25T16:15:33.085868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for h11:0.3838, Test accuracy for h11: 0.3852\n",
      "Train accuracy for h21:0.5351, Test accuracy for h21: 0.5350\n",
      "Train accuracy for h31:0.1309, Test accuracy for h31: 0.1267\n",
      "Train accuracy for h22:0.0348, Test accuracy for h22: 0.0329\n"
     ]
    }
   ],
   "source": [
    "train_acc, test_acc = calc_accuracy_mr(model, train_gen , test_gen, device = device, cnn= False)\n",
    "print(f'Train accuracy for h11:{train_acc[0]:.4f}, Test accuracy for h11: {test_acc[0]:.4f}')\n",
    "print(f'Train accuracy for h21:{train_acc[1]:.4f}, Test accuracy for h21: {test_acc[1]:.4f}')\n",
    "print(f'Train accuracy for h31:{train_acc[2]:.4f}, Test accuracy for h31: {test_acc[2]:.4f}')\n",
    "print(f'Train accuracy for h22:{train_acc[3]:.4f}, Test accuracy for h22: {test_acc[3]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "171a66c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-25T16:15:55.430193Z",
     "iopub.status.busy": "2024-03-25T16:15:55.429891Z",
     "iopub.status.idle": "2024-03-25T16:15:55.445749Z",
     "shell.execute_reply": "2024-03-25T16:15:55.444853Z"
    },
    "papermill": {
     "duration": 0.044342,
     "end_time": "2024-03-25T16:15:55.447888",
     "exception": false,
     "start_time": "2024-03-25T16:15:55.403546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, '/kaggle/working/saved_models/CNN_GRU_hybrid_cicy4_Hodge_v1.pt')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4575883,
     "sourceId": 7936105,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9033.124725,
   "end_time": "2024-03-25T16:15:58.287884",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-25T13:45:25.163159",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
