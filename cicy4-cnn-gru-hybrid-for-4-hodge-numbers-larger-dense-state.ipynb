{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b4347b",
   "metadata": {
    "papermill": {
     "duration": 0.007919,
     "end_time": "2024-03-28T06:48:34.021462",
     "exception": false,
     "start_time": "2024-03-28T06:48:34.013543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CICY4:CNN-GRU hybrid for 4 Hodge numbers\n",
    "\n",
    "- V1: Use ReduceLROnPlateau with GRU block (20, 64, 6, 4), train loss ~ 9.0\n",
    "- V2: Use OneCycleLR: train loss ~ 900 (bad result)\n",
    "- V3 Use CosineAnnealingLR: train loss ~ 60 (bad result)\n",
    "- V4: Use ReduceLROnPlateau again, but with higher max LR (bad result)\n",
    "- V5/V6: Change the GRU block architecture to have fewer layers, but with larger size for the hidden layer (100 -> 128), increase the size of the dense layers. Use ReduceLROnPlateau with max learning rate of 0.1, min LR of 1e-6. Very good result obtained: (81, 69, 48, 13) accuracy for (h11, h21, h31, h22). Train loss ~ 3.0, test loss ~ 6.0\n",
    "- V7/V8: Increase the hidden size of the GRU block from 128->256 and reduce the num_layer from 4-> 2. Same learning parameters as V5. (84, 74, 52, 19)\n",
    "- V9: Change the CNN block to have filters [128,128,64], GRU block is (20,256,1,4)\n",
    "- V10: Use the same architecture as V8, with more complex dense layers: 1 more layers  (with Relu activation)\n",
    "\n",
    "For GRU block, the standalone best model so far has the parameters (in_channels, hidden_size, num_layers, outputs) =  (20, 64, 6, 4). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e6d7b8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-28T06:48:34.037980Z",
     "iopub.status.busy": "2024-03-28T06:48:34.037358Z",
     "iopub.status.idle": "2024-03-28T06:48:39.500081Z",
     "shell.execute_reply": "2024-03-28T06:48:39.499195Z"
    },
    "papermill": {
     "duration": 5.473441,
     "end_time": "2024-03-28T06:48:39.502369",
     "exception": false,
     "start_time": "2024-03-28T06:48:34.028928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "334e6318",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:48:39.519468Z",
     "iopub.status.busy": "2024-03-28T06:48:39.519054Z",
     "iopub.status.idle": "2024-03-28T06:48:58.124285Z",
     "shell.execute_reply": "2024-03-28T06:48:58.123313Z"
    },
    "papermill": {
     "duration": 18.616021,
     "end_time": "2024-03-28T06:48:58.126265",
     "exception": false,
     "start_time": "2024-03-28T06:48:39.510244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((921497, 16, 20), (921497, 4), (921497,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "path = '/kaggle/input/calabi-yau-cicy-4-folds/'\n",
    "\n",
    "conf = np.load('/kaggle/input/calabi-yau-cicy-4-folds/conf.npy')\n",
    "hodge = np.load(os.path.join(path, 'hodge.npy'))\n",
    "direct = np.load(os.path.join(path, 'direct.npy'))\n",
    "conf.shape, hodge.shape, direct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3698b9d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:48:58.143066Z",
     "iopub.status.busy": "2024-03-28T06:48:58.142739Z",
     "iopub.status.idle": "2024-03-28T06:48:58.146978Z",
     "shell.execute_reply": "2024-03-28T06:48:58.146140Z"
    },
    "papermill": {
     "duration": 0.014832,
     "end_time": "2024-03-28T06:48:58.148961",
     "exception": false,
     "start_time": "2024-03-28T06:48:58.134129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('saved_models'):\n",
    "    os.makedirs('saved_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d1c6bc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:48:58.164993Z",
     "iopub.status.busy": "2024-03-28T06:48:58.164716Z",
     "iopub.status.idle": "2024-03-28T06:48:58.266228Z",
     "shell.execute_reply": "2024-03-28T06:48:58.265364Z"
    },
    "papermill": {
     "duration": 0.111768,
     "end_time": "2024-03-28T06:48:58.268176",
     "exception": false,
     "start_time": "2024-03-28T06:48:58.156408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/calabi-yau-cicy-4-folds')\n",
    "from CICY4_functions import data_generator, batch_gd_scheduler,  calc_accuracy_mr, plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a3f4ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:48:58.285129Z",
     "iopub.status.busy": "2024-03-28T06:48:58.284879Z",
     "iopub.status.idle": "2024-03-28T06:48:58.492068Z",
     "shell.execute_reply": "2024-03-28T06:48:58.491270Z"
    },
    "papermill": {
     "duration": 0.21873,
     "end_time": "2024-03-28T06:48:58.494358",
     "exception": false,
     "start_time": "2024-03-28T06:48:58.275628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test(X, y):\n",
    "    X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 101, shuffle = True)\n",
    "    \n",
    "    X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "    #only need reshape if the y dimension is 1\n",
    "    #y_train = torch.from_numpy(y_train.astype(np.float32).reshape(-1, 1))\n",
    "    y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "\n",
    "    X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "    #y_test = torch.from_numpy(y_test.astype(np.float32).reshape(-1, 1))\n",
    "    y_test = torch.from_numpy(y_test.astype(np.float32))                         \n",
    "    \n",
    "    print(f'X_train shape: {X_train.shape}, \\n y_train shape:{y_train.shape},\\\n",
    "                 \\n X_test shape: {X_test.shape}, \\n y_test shape:{y_test.shape}')\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60cf99a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:48:58.512492Z",
     "iopub.status.busy": "2024-03-28T06:48:58.512210Z",
     "iopub.status.idle": "2024-03-28T06:48:59.845555Z",
     "shell.execute_reply": "2024-03-28T06:48:59.844530Z"
    },
    "papermill": {
     "duration": 1.344229,
     "end_time": "2024-03-28T06:48:59.847715",
     "exception": false,
     "start_time": "2024-03-28T06:48:58.503486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([737197, 16, 20]), \n",
      " y_train shape:torch.Size([737197, 4]),                 \n",
      " X_test shape: torch.Size([184300, 16, 20]), \n",
      " y_test shape:torch.Size([184300, 4])\n"
     ]
    }
   ],
   "source": [
    "X = conf\n",
    "y = hodge\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test(X, y)\n",
    "\n",
    "train_gen = lambda: data_generator(X_train, y_train)\n",
    "test_gen = lambda: data_generator(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87bcc96f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:48:59.864702Z",
     "iopub.status.busy": "2024-03-28T06:48:59.864394Z",
     "iopub.status.idle": "2024-03-28T06:48:59.916705Z",
     "shell.execute_reply": "2024-03-28T06:48:59.915816Z"
    },
    "papermill": {
     "duration": 0.06322,
     "end_time": "2024-03-28T06:48:59.918990",
     "exception": false,
     "start_time": "2024-03-28T06:48:59.855770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7312a4",
   "metadata": {
    "papermill": {
     "duration": 0.007498,
     "end_time": "2024-03-28T06:48:59.934102",
     "exception": false,
     "start_time": "2024-03-28T06:48:59.926604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CNN-RNN hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7c684f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:48:59.950362Z",
     "iopub.status.busy": "2024-03-28T06:48:59.950070Z",
     "iopub.status.idle": "2024-03-28T06:48:59.957176Z",
     "shell.execute_reply": "2024-03-28T06:48:59.956334Z"
    },
    "papermill": {
     "duration": 0.017361,
     "end_time": "2024-03-28T06:48:59.959025",
     "exception": false,
     "start_time": "2024-03-28T06:48:59.941664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################### CNN ###############################\n",
    "class CNN_block(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,128, 4, 1)\n",
    "        #self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.conv2 = nn.Conv2d(128, 64, 3, 1)\n",
    "        #self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.mxpool = nn.MaxPool2d(2,2)\n",
    "        #self.conv3 = nn.Conv2d(128,64, 2, 1)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.conv_total = nn.Sequential(\n",
    "            self.conv1,\n",
    "            #self.bn1,\n",
    "            self.mxpool,\n",
    "            #self.bn2,\n",
    "            self.conv2,\n",
    "            self.mxpool,\n",
    "            #self.conv3,\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv_total(x))\n",
    "        #reshape is the same as flat(x)\n",
    "        #x = x.reshape(x.shape[0], -1)\n",
    "        x = self.flat(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd92da77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:48:59.975301Z",
     "iopub.status.busy": "2024-03-28T06:48:59.975031Z",
     "iopub.status.idle": "2024-03-28T06:49:00.156118Z",
     "shell.execute_reply": "2024-03-28T06:49:00.155126Z"
    },
    "papermill": {
     "duration": 0.191557,
     "end_time": "2024-03-28T06:49:00.158141",
     "exception": false,
     "start_time": "2024-03-28T06:48:59.966584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_block(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (mxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (conv_total): Sequential(\n",
       "    (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_block = CNN_block()\n",
    "cnn_block.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bb99716",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:49:00.175443Z",
     "iopub.status.busy": "2024-03-28T06:49:00.174734Z",
     "iopub.status.idle": "2024-03-28T06:49:00.182253Z",
     "shell.execute_reply": "2024-03-28T06:49:00.181393Z"
    },
    "papermill": {
     "duration": 0.018189,
     "end_time": "2024-03-28T06:49:00.184293",
     "exception": false,
     "start_time": "2024-03-28T06:49:00.166104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RNN_block(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden, n_rnnlayers, n_outputs):\n",
    "        super(RNN_block,self).__init__()\n",
    "        self.D = n_inputs\n",
    "        self.M = n_hidden\n",
    "        self.K = n_outputs\n",
    "        self.L = n_rnnlayers        \n",
    "        #self.lstm = nn.LSTM(input_size = self.D,\n",
    "        #                   hidden_size = self.M,\n",
    "        #                   num_layers = self.L,\n",
    "        #                   batch_first = True)    \n",
    "        self.gru = nn.GRU(input_size = self.D,\n",
    "                           hidden_size = self.M,\n",
    "                           num_layers = self.L,\n",
    "                           batch_first = True)\n",
    "        #self.fc1 = nn.Linear(self.M, 128)\n",
    "        #self.fc2 = nn.Linear(128, self.K)\n",
    "    def forward(self, X):\n",
    "        #input X is NxTxD\n",
    "        #initial hidden states\n",
    "        h0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
    "        #c0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
    "        #get LSTM unit output:\n",
    "        #output is NxTxM\n",
    "        #out, _ = self.lstm(X, (h0,c0))\n",
    "        out, _ = self.gru(X, h0)   \n",
    "        #we only want h(T) at the final time step\n",
    "        # output is now of shape (N, M)\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93704e08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:49:00.200835Z",
     "iopub.status.busy": "2024-03-28T06:49:00.200532Z",
     "iopub.status.idle": "2024-03-28T06:49:00.329897Z",
     "shell.execute_reply": "2024-03-28T06:49:00.328994Z"
    },
    "papermill": {
     "duration": 0.13996,
     "end_time": "2024-03-28T06:49:00.332021",
     "exception": false,
     "start_time": "2024-03-28T06:49:00.192061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_block(\n",
       "  (gru): GRU(20, 256, num_layers=2, batch_first=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gru_block = RNN_block(20, 64, 6, 4)\n",
    "#gru_block = RNN_block(20, 128, 4, 4)\n",
    "gru_block = RNN_block(20, 256, 2, 4)\n",
    "gru_block.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1edb86b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:49:00.349132Z",
     "iopub.status.busy": "2024-03-28T06:49:00.348847Z",
     "iopub.status.idle": "2024-03-28T06:49:00.356700Z",
     "shell.execute_reply": "2024-03-28T06:49:00.356013Z"
    },
    "papermill": {
     "duration": 0.018444,
     "end_time": "2024-03-28T06:49:00.358469",
     "exception": false,
     "start_time": "2024-03-28T06:49:00.340025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN_RNN_hybrid(nn.Module):\n",
    "    def __init__(self, cnn_block, rnn_block, feat_vec_size):\n",
    "        super(CNN_RNN_hybrid, self).__init__()\n",
    "        self.cnn_block = cnn_block\n",
    "        self.rnn_block = rnn_block\n",
    "        self.feat_vec_size = feat_vec_size\n",
    "        self.fc1 = nn.Linear(self.feat_vec_size, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #output of cnn block is (N,384)\n",
    "        x1 = x.view(-1,1, 16,20)\n",
    "        x1 = self.cnn_block(x1)\n",
    "        #output of rnn block is (N,M = 64)\n",
    "        x2 = self.rnn_block(x)\n",
    "        #concatenate the 2 outputs to produce a feat vec (N, M+384)\n",
    "        xx = torch.cat([x1, x2], dim = 1)\n",
    "        # pass through linear layers\n",
    "        xx = F.relu(self.fc1(xx))\n",
    "        xx = F.relu(self.fc2(xx))\n",
    "        #final output is 4\n",
    "        xx = self.fc3(xx)\n",
    "        \n",
    "        return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8f7e1b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:49:00.375250Z",
     "iopub.status.busy": "2024-03-28T06:49:00.375008Z",
     "iopub.status.idle": "2024-03-28T06:49:00.395325Z",
     "shell.execute_reply": "2024-03-28T06:49:00.394531Z"
    },
    "papermill": {
     "duration": 0.030898,
     "end_time": "2024-03-28T06:49:00.397162",
     "exception": false,
     "start_time": "2024-03-28T06:49:00.366264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_RNN_hybrid(\n",
       "  (cnn_block): CNN_block(\n",
       "    (conv1): Conv2d(1, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (conv2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (mxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "    (conv_total): Sequential(\n",
       "      (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (rnn_block): RNN_block(\n",
       "    (gru): GRU(20, 256, num_layers=2, batch_first=True)\n",
       "  )\n",
       "  (fc1): Linear(in_features=640, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN_RNN_hybrid(cnn_block, gru_block, 256+384)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46dbc9cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:49:00.414078Z",
     "iopub.status.busy": "2024-03-28T06:49:00.413841Z",
     "iopub.status.idle": "2024-03-28T06:49:00.418373Z",
     "shell.execute_reply": "2024-03-28T06:49:00.417543Z"
    },
    "papermill": {
     "duration": 0.015443,
     "end_time": "2024-03-28T06:49:00.420648",
     "exception": false,
     "start_time": "2024-03-28T06:49:00.405205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1867460\n"
     ]
    }
   ],
   "source": [
    "#count the number of parameters in the model\n",
    "params = [p.numel() for p in model.parameters() if p.requires_grad]\n",
    "print(sum(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a84cd8",
   "metadata": {
    "papermill": {
     "duration": 0.007996,
     "end_time": "2024-03-28T06:49:00.436595",
     "exception": false,
     "start_time": "2024-03-28T06:49:00.428599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Shape Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ad4b4ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:49:00.454372Z",
     "iopub.status.busy": "2024-03-28T06:49:00.453736Z",
     "iopub.status.idle": "2024-03-28T06:49:00.580190Z",
     "shell.execute_reply": "2024-03-28T06:49:00.579266Z"
    },
    "papermill": {
     "duration": 0.137793,
     "end_time": "2024-03-28T06:49:00.582377",
     "exception": false,
     "start_time": "2024-03-28T06:49:00.444584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN BLOCK SHAPE TRACING\n",
      "Original shape of the image before passing through the network: \n",
      " torch.Size([16, 20])\n",
      "\n",
      "Reshape the size to take in account the batch number\n",
      "The new size is torch.Size([1, 16, 20])\n",
      "\n",
      "Shape of the image after passing through the GRU(20, 256, num_layers=2, batch_first=True): \n",
      " torch.Size([1, 16, 256])\n",
      "\n",
      "The final output shape is torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "X = X_train[0].to(device)\n",
    "y = y_train[0].to(device)\n",
    "print('RNN BLOCK SHAPE TRACING')\n",
    "print(f'Original shape of the image before passing through the network: \\n {X.shape}\\n')\n",
    "\n",
    "print('Reshape the size to take in account the batch number')\n",
    "X = X.view(1,16,20)\n",
    "print(f'The new size is {X.shape}\\n')\n",
    "\n",
    "h0 = torch.zeros(gru_block.L, X.size(0), gru_block.M).to(device)\n",
    "#c0 = torch.zeros(gru_block.L, X.size(0), gru_block.M).to(device)\n",
    "X, _ = gru_block.gru(X, h0)\n",
    "print(f'Shape of the image after passing through the {gru_block.gru}: \\n {X.shape}\\n')\n",
    "\n",
    "#get only the h(T) at the last time step\n",
    "Xg = X[:, -1, :]\n",
    "print(f'The final output shape is {Xg.shape}')\n",
    "#print(X)\n",
    "#print(f'Target: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1c0b03f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:49:00.600025Z",
     "iopub.status.busy": "2024-03-28T06:49:00.599726Z",
     "iopub.status.idle": "2024-03-28T06:49:01.011994Z",
     "shell.execute_reply": "2024-03-28T06:49:01.011096Z"
    },
    "papermill": {
     "duration": 0.423422,
     "end_time": "2024-03-28T06:49:01.014077",
     "exception": false,
     "start_time": "2024-03-28T06:49:00.590655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN BLOCK SHAPE TRACING\n",
      "Original shape of the image before passing through the network: \n",
      " torch.Size([16, 20])\n",
      "\n",
      "Reshape the size to take in account the batch number\n",
      "The new size is torch.Size([1, 1, 16, 20])\n",
      "\n",
      "Original shape of the image after passing through Sequential(\n",
      "  (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "): \n",
      " torch.Size([1, 64, 2, 3])\n",
      "\n",
      "Original shape of the image after passing through Flatten(start_dim=1, end_dim=-1): \n",
      " torch.Size([1, 384])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = X_train[0].to(device)\n",
    "print('CNN BLOCK SHAPE TRACING')\n",
    "print(f'Original shape of the image before passing through the network: \\n {X.shape}\\n')\n",
    "\n",
    "print('Reshape the size to take in account the batch number')\n",
    "X = X.view(1,1,16,20)\n",
    "print(f'The new size is {X.shape}\\n')\n",
    "\n",
    "X = cnn_block.conv_total(X)\n",
    "print(f'Original shape of the image after passing through {cnn_block.conv_total}: \\n {X.shape}\\n')\n",
    "\n",
    "#X = X.reshape(X.shape[0], -1)\n",
    "#print(f'After reshaping: {X.shape}') [1,384]\n",
    "Xc = cnn_block.flat(X)\n",
    "print(f'Original shape of the image after passing through {cnn_block.flat}: \\n {Xc.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abd2d904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:49:01.032199Z",
     "iopub.status.busy": "2024-03-28T06:49:01.031924Z",
     "iopub.status.idle": "2024-03-28T06:49:01.059949Z",
     "shell.execute_reply": "2024-03-28T06:49:01.059072Z"
    },
    "papermill": {
     "duration": 0.039108,
     "end_time": "2024-03-28T06:49:01.061754",
     "exception": false,
     "start_time": "2024-03-28T06:49:01.022646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 256]), torch.Size([1, 384]), torch.Size([1, 640]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat = torch.cat([Xc, Xg], dim=1) \n",
    "Xg.shape, Xc.shape, X_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed106516",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:49:01.079692Z",
     "iopub.status.busy": "2024-03-28T06:49:01.079445Z",
     "iopub.status.idle": "2024-03-28T06:49:01.125840Z",
     "shell.execute_reply": "2024-03-28T06:49:01.124758Z"
    },
    "papermill": {
     "duration": 0.057575,
     "end_time": "2024-03-28T06:49:01.127822",
     "exception": false,
     "start_time": "2024-03-28T06:49:01.070247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-RNN HYBRID BLOCK SHAPE TRACING\n",
      "Original shape of the image before passing through the network: \n",
      " torch.Size([16, 20])\n",
      "\n",
      "Reshape the size to take in account the batch number\n",
      "The new size is torch.Size([1, 16, 20])\n",
      "\n",
      "Shape  after passing through the entire network: \n",
      " torch.Size([1, 4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = X_train[0].to(device)\n",
    "print('CNN-RNN HYBRID BLOCK SHAPE TRACING')\n",
    "print(f'Original shape of the image before passing through the network: \\n {X.shape}\\n')\n",
    "\n",
    "print('Reshape the size to take in account the batch number')\n",
    "X = X.view(1,16,20)\n",
    "print(f'The new size is {X.shape}\\n')\n",
    "\n",
    "X = model(X)\n",
    "print(f'Shape  after passing through the entire network: \\n {X.shape}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35966020",
   "metadata": {
    "papermill": {
     "duration": 0.008295,
     "end_time": "2024-03-28T06:49:01.144743",
     "exception": false,
     "start_time": "2024-03-28T06:49:01.136448",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train loop with scheduler\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.OneCycleLR.html\n",
    "\n",
    "https://residentmario.github.io/pytorch-training-performance-guide/lr-sched-and-optim.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4693e598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:49:01.163191Z",
     "iopub.status.busy": "2024-03-28T06:49:01.162650Z",
     "iopub.status.idle": "2024-03-28T06:49:03.561552Z",
     "shell.execute_reply": "2024-03-28T06:49:03.560584Z"
    },
    "papermill": {
     "duration": 2.410479,
     "end_time": "2024-03-28T06:49:03.563869",
     "exception": false,
     "start_time": "2024-03-28T06:49:01.153390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_epoch = 300\n",
    "criterion = nn.MSELoss()\n",
    "batch_size = 128\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "#optimizer = torch.optim.SGD(model.parameters())\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.01)\n",
    "\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', min_lr = 1e-6)\n",
    "#scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e7f2fc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T06:49:03.583590Z",
     "iopub.status.busy": "2024-03-28T06:49:03.583182Z",
     "iopub.status.idle": "2024-03-28T09:55:34.717799Z",
     "shell.execute_reply": "2024-03-28T09:55:34.716843Z"
    },
    "papermill": {
     "duration": 11191.243512,
     "end_time": "2024-03-28T09:55:34.816932",
     "exception": false,
     "start_time": "2024-03-28T06:49:03.573420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/300, train loss:  377.6222          test_loss:  199.5626, duration: 0:00:37.810845,           learning rate: (0.01, 0.01)\n",
      "Epoch: 2/300, train loss:  189.0265          test_loss:  190.9440, duration: 0:00:37.237458,           learning rate: (0.01, 0.01)\n",
      "Epoch: 3/300, train loss:  173.8727          test_loss:  144.3783, duration: 0:00:37.213705,           learning rate: (0.01, 0.01)\n",
      "Epoch: 4/300, train loss:  158.5721          test_loss:  163.7347, duration: 0:00:37.355029,           learning rate: (0.01, 0.01)\n",
      "Epoch: 5/300, train loss:  146.9035          test_loss:  138.9262, duration: 0:00:37.858966,           learning rate: (0.01, 0.01)\n",
      "Epoch: 6/300, train loss:  141.1835          test_loss:  123.3905, duration: 0:00:37.071268,           learning rate: (0.01, 0.01)\n",
      "Epoch: 7/300, train loss:  137.3645          test_loss:  148.8776, duration: 0:00:37.165027,           learning rate: (0.01, 0.01)\n",
      "Epoch: 8/300, train loss:  134.4471          test_loss:  123.0403, duration: 0:00:37.162280,           learning rate: (0.01, 0.01)\n",
      "Epoch: 9/300, train loss:  132.0700          test_loss:  133.6972, duration: 0:00:37.092753,           learning rate: (0.01, 0.01)\n",
      "Epoch: 10/300, train loss:  128.7488          test_loss:  124.6067, duration: 0:00:37.244222,           learning rate: (0.01, 0.01)\n",
      "Epoch: 11/300, train loss:  130.3157          test_loss:  131.8964, duration: 0:00:37.317514,           learning rate: (0.01, 0.01)\n",
      "Epoch: 12/300, train loss:  210.9649          test_loss:  149.6220, duration: 0:00:37.141556,           learning rate: (0.01, 0.01)\n",
      "Epoch: 13/300, train loss:  136.2118          test_loss:  123.6381, duration: 0:00:37.286822,           learning rate: (0.01, 0.01)\n",
      "Epoch: 14/300, train loss:  129.2673          test_loss:  121.3862, duration: 0:00:37.420147,           learning rate: (0.01, 0.01)\n",
      "Epoch: 15/300, train loss:  147.2104          test_loss:  124.2350, duration: 0:00:37.376222,           learning rate: (0.01, 0.01)\n",
      "Epoch: 16/300, train loss:  127.4491          test_loss:  116.2356, duration: 0:00:37.254936,           learning rate: (0.01, 0.01)\n",
      "Epoch: 17/300, train loss:  123.3069          test_loss:  119.4259, duration: 0:00:37.394595,           learning rate: (0.01, 0.01)\n",
      "Epoch: 18/300, train loss:  121.7443          test_loss:  128.1308, duration: 0:00:37.195056,           learning rate: (0.01, 0.01)\n",
      "Epoch: 19/300, train loss:  121.5106          test_loss:  113.0740, duration: 0:00:37.234931,           learning rate: (0.01, 0.01)\n",
      "Epoch: 20/300, train loss:  119.3980          test_loss:  110.6440, duration: 0:00:37.218731,           learning rate: (0.01, 0.01)\n",
      "Epoch: 21/300, train loss:  119.2893          test_loss:  111.1050, duration: 0:00:37.318049,           learning rate: (0.01, 0.01)\n",
      "Epoch: 22/300, train loss:  120.5742          test_loss:  128.4186, duration: 0:00:37.237693,           learning rate: (0.01, 0.01)\n",
      "Epoch: 23/300, train loss:  117.7475          test_loss:  137.4693, duration: 0:00:37.279741,           learning rate: (0.01, 0.01)\n",
      "Epoch: 24/300, train loss:  116.6773          test_loss:  107.6796, duration: 0:00:37.083610,           learning rate: (0.01, 0.01)\n",
      "Epoch: 25/300, train loss:  120.3469          test_loss:  114.3444, duration: 0:00:36.992658,           learning rate: (0.01, 0.01)\n",
      "Epoch: 26/300, train loss:  117.2628          test_loss:  116.1042, duration: 0:00:37.152175,           learning rate: (0.01, 0.01)\n",
      "Epoch: 27/300, train loss:  116.9546          test_loss:  107.6470, duration: 0:00:37.225326,           learning rate: (0.01, 0.01)\n",
      "Epoch: 28/300, train loss:  116.9926          test_loss:  114.9758, duration: 0:00:37.572279,           learning rate: (0.01, 0.01)\n",
      "Epoch: 29/300, train loss:  116.1170          test_loss:  112.1352, duration: 0:00:37.304948,           learning rate: (0.01, 0.01)\n",
      "Epoch: 30/300, train loss:  116.6774          test_loss:  113.7192, duration: 0:00:36.929724,           learning rate: (0.01, 0.01)\n",
      "Epoch: 31/300, train loss:  117.2990          test_loss:  130.2279, duration: 0:00:37.306942,           learning rate: (0.01, 0.01)\n",
      "Epoch: 32/300, train loss:  116.5054          test_loss:  104.6730, duration: 0:00:37.300971,           learning rate: (0.01, 0.01)\n",
      "Epoch: 33/300, train loss:  116.5293          test_loss:  113.0271, duration: 0:00:36.969969,           learning rate: (0.01, 0.01)\n",
      "Epoch: 34/300, train loss:  117.1888          test_loss:  107.4057, duration: 0:00:37.220772,           learning rate: (0.01, 0.01)\n",
      "Epoch: 35/300, train loss:  114.6951          test_loss:  137.3021, duration: 0:00:37.365664,           learning rate: (0.01, 0.01)\n",
      "Epoch: 36/300, train loss:  116.1060          test_loss:  116.9996, duration: 0:00:37.105938,           learning rate: (0.01, 0.01)\n",
      "Epoch: 37/300, train loss:  115.8798          test_loss:  120.3714, duration: 0:00:37.314625,           learning rate: (0.01, 0.01)\n",
      "Epoch: 38/300, train loss:  115.5854          test_loss:  123.0826, duration: 0:00:37.383176,           learning rate: (0.01, 0.01)\n",
      "Epoch: 39/300, train loss:  114.4935          test_loss:  110.1083, duration: 0:00:37.548398,           learning rate: (0.01, 0.01)\n",
      "Epoch: 40/300, train loss:  116.0983          test_loss:  108.7502, duration: 0:00:37.157916,           learning rate: (0.01, 0.01)\n",
      "Epoch: 41/300, train loss:  115.3637          test_loss:  114.6154, duration: 0:00:37.334080,           learning rate: (0.01, 0.01)\n",
      "Epoch: 42/300, train loss:  136.0765          test_loss:  117.5138, duration: 0:00:36.983089,           learning rate: (0.01, 0.01)\n",
      "Epoch: 43/300, train loss:  114.2182          test_loss:  108.0929, duration: 0:00:37.031805,           learning rate: (0.01, 0.001)\n",
      "Epoch: 44/300, train loss:  75.8696          test_loss:  76.8292, duration: 0:00:37.198201,           learning rate: (0.001, 0.001)\n",
      "Epoch: 45/300, train loss:  68.7464          test_loss:  72.6652, duration: 0:00:37.014628,           learning rate: (0.001, 0.001)\n",
      "Epoch: 46/300, train loss:  65.2486          test_loss:  70.1000, duration: 0:00:37.163732,           learning rate: (0.001, 0.001)\n",
      "Epoch: 47/300, train loss:  62.6807          test_loss:  69.5063, duration: 0:00:37.094040,           learning rate: (0.001, 0.001)\n",
      "Epoch: 48/300, train loss:  60.7933          test_loss:  67.6904, duration: 0:00:36.988814,           learning rate: (0.001, 0.001)\n",
      "Epoch: 49/300, train loss:  59.3498          test_loss:  66.5465, duration: 0:00:37.044937,           learning rate: (0.001, 0.001)\n",
      "Epoch: 50/300, train loss:  58.1105          test_loss:  67.7668, duration: 0:00:37.388016,           learning rate: (0.001, 0.001)\n",
      "Epoch: 51/300, train loss:  57.0899          test_loss:  63.0916, duration: 0:00:36.948028,           learning rate: (0.001, 0.001)\n",
      "Epoch: 52/300, train loss:  56.3683          test_loss:  64.4462, duration: 0:00:36.795583,           learning rate: (0.001, 0.001)\n",
      "Epoch: 53/300, train loss:  55.4787          test_loss:  63.3608, duration: 0:00:37.168335,           learning rate: (0.001, 0.001)\n",
      "Epoch: 54/300, train loss:  54.6884          test_loss:  63.5602, duration: 0:00:37.144554,           learning rate: (0.001, 0.001)\n",
      "Epoch: 55/300, train loss:  54.3317          test_loss:  63.9526, duration: 0:00:37.159244,           learning rate: (0.001, 0.001)\n",
      "Epoch: 56/300, train loss:  53.6363          test_loss:  65.0542, duration: 0:00:36.812103,           learning rate: (0.001, 0.001)\n",
      "Epoch: 57/300, train loss:  53.0816          test_loss:  63.3551, duration: 0:00:37.225725,           learning rate: (0.001, 0.001)\n",
      "Epoch: 58/300, train loss:  52.5817          test_loss:  59.7035, duration: 0:00:36.883568,           learning rate: (0.001, 0.001)\n",
      "Epoch: 59/300, train loss:  51.9820          test_loss:  66.3971, duration: 0:00:37.044867,           learning rate: (0.001, 0.001)\n",
      "Epoch: 60/300, train loss:  51.6783          test_loss:  60.3414, duration: 0:00:37.121409,           learning rate: (0.001, 0.001)\n",
      "Epoch: 61/300, train loss:  51.0061          test_loss:  67.1774, duration: 0:00:37.340777,           learning rate: (0.001, 0.001)\n",
      "Epoch: 62/300, train loss:  50.7637          test_loss:  59.3728, duration: 0:00:37.302825,           learning rate: (0.001, 0.001)\n",
      "Epoch: 63/300, train loss:  50.4909          test_loss:  58.5464, duration: 0:00:37.058463,           learning rate: (0.001, 0.001)\n",
      "Epoch: 64/300, train loss:  50.1964          test_loss:  63.3777, duration: 0:00:36.999283,           learning rate: (0.001, 0.001)\n",
      "Epoch: 65/300, train loss:  49.7962          test_loss:  63.1408, duration: 0:00:36.907610,           learning rate: (0.001, 0.001)\n",
      "Epoch: 66/300, train loss:  49.6252          test_loss:  56.6169, duration: 0:00:37.231178,           learning rate: (0.001, 0.001)\n",
      "Epoch: 67/300, train loss:  49.3331          test_loss:  59.4166, duration: 0:00:36.979890,           learning rate: (0.001, 0.001)\n",
      "Epoch: 68/300, train loss:  48.9265          test_loss:  57.8629, duration: 0:00:37.119150,           learning rate: (0.001, 0.001)\n",
      "Epoch: 69/300, train loss:  48.6099          test_loss:  56.1942, duration: 0:00:37.056010,           learning rate: (0.001, 0.001)\n",
      "Epoch: 70/300, train loss:  48.4846          test_loss:  56.1020, duration: 0:00:36.962281,           learning rate: (0.001, 0.001)\n",
      "Epoch: 71/300, train loss:  48.1954          test_loss:  55.5101, duration: 0:00:37.161693,           learning rate: (0.001, 0.001)\n",
      "Epoch: 72/300, train loss:  47.6812          test_loss:  56.3468, duration: 0:00:37.088588,           learning rate: (0.001, 0.001)\n",
      "Epoch: 73/300, train loss:  47.6288          test_loss:  57.4543, duration: 0:00:37.166068,           learning rate: (0.001, 0.001)\n",
      "Epoch: 74/300, train loss:  47.3031          test_loss:  53.3940, duration: 0:00:37.169729,           learning rate: (0.001, 0.001)\n",
      "Epoch: 75/300, train loss:  47.0518          test_loss:  57.8024, duration: 0:00:36.874915,           learning rate: (0.001, 0.001)\n",
      "Epoch: 76/300, train loss:  47.0381          test_loss:  54.9615, duration: 0:00:36.974159,           learning rate: (0.001, 0.001)\n",
      "Epoch: 77/300, train loss:  46.5966          test_loss:  53.3761, duration: 0:00:37.258249,           learning rate: (0.001, 0.001)\n",
      "Epoch: 78/300, train loss:  46.3169          test_loss:  56.8216, duration: 0:00:36.868073,           learning rate: (0.001, 0.001)\n",
      "Epoch: 79/300, train loss:  46.0520          test_loss:  56.7741, duration: 0:00:36.844958,           learning rate: (0.001, 0.001)\n",
      "Epoch: 80/300, train loss:  46.0395          test_loss:  56.5544, duration: 0:00:37.074340,           learning rate: (0.001, 0.001)\n",
      "Epoch: 81/300, train loss:  45.5058          test_loss:  56.3656, duration: 0:00:37.251548,           learning rate: (0.001, 0.001)\n",
      "Epoch: 82/300, train loss:  45.5858          test_loss:  56.2148, duration: 0:00:37.669131,           learning rate: (0.001, 0.001)\n",
      "Epoch: 83/300, train loss:  45.5129          test_loss:  53.1338, duration: 0:00:37.066192,           learning rate: (0.001, 0.001)\n",
      "Epoch: 84/300, train loss:  45.1946          test_loss:  59.3918, duration: 0:00:37.358925,           learning rate: (0.001, 0.001)\n",
      "Epoch: 85/300, train loss:  44.9006          test_loss:  53.8527, duration: 0:00:36.848131,           learning rate: (0.001, 0.001)\n",
      "Epoch: 86/300, train loss:  45.0209          test_loss:  55.0667, duration: 0:00:37.076052,           learning rate: (0.001, 0.001)\n",
      "Epoch: 87/300, train loss:  44.6368          test_loss:  52.3631, duration: 0:00:36.955965,           learning rate: (0.001, 0.001)\n",
      "Epoch: 88/300, train loss:  44.4208          test_loss:  52.5857, duration: 0:00:37.109833,           learning rate: (0.001, 0.001)\n",
      "Epoch: 89/300, train loss:  44.3886          test_loss:  56.0317, duration: 0:00:36.895862,           learning rate: (0.001, 0.001)\n",
      "Epoch: 90/300, train loss:  44.0281          test_loss:  51.9188, duration: 0:00:37.164483,           learning rate: (0.001, 0.001)\n",
      "Epoch: 91/300, train loss:  43.9598          test_loss:  54.1000, duration: 0:00:37.091143,           learning rate: (0.001, 0.001)\n",
      "Epoch: 92/300, train loss:  44.1316          test_loss:  52.8120, duration: 0:00:37.158723,           learning rate: (0.001, 0.001)\n",
      "Epoch: 93/300, train loss:  43.5869          test_loss:  60.9100, duration: 0:00:36.908390,           learning rate: (0.001, 0.001)\n",
      "Epoch: 94/300, train loss:  43.8189          test_loss:  50.3890, duration: 0:00:37.172291,           learning rate: (0.001, 0.001)\n",
      "Epoch: 95/300, train loss:  43.9768          test_loss:  51.5900, duration: 0:00:37.131596,           learning rate: (0.001, 0.001)\n",
      "Epoch: 96/300, train loss:  43.4373          test_loss:  52.6727, duration: 0:00:36.858192,           learning rate: (0.001, 0.001)\n",
      "Epoch: 97/300, train loss:  43.4033          test_loss:  51.4820, duration: 0:00:37.321858,           learning rate: (0.001, 0.001)\n",
      "Epoch: 98/300, train loss:  43.2056          test_loss:  59.3337, duration: 0:00:37.336945,           learning rate: (0.001, 0.001)\n",
      "Epoch: 99/300, train loss:  43.2004          test_loss:  56.6469, duration: 0:00:37.213888,           learning rate: (0.001, 0.001)\n",
      "Epoch: 100/300, train loss:  43.3453          test_loss:  51.2984, duration: 0:00:37.757525,           learning rate: (0.001, 0.001)\n",
      "Epoch: 101/300, train loss:  43.0118          test_loss:  51.0770, duration: 0:00:37.333374,           learning rate: (0.001, 0.001)\n",
      "Epoch: 102/300, train loss:  42.7542          test_loss:  52.9028, duration: 0:00:37.406918,           learning rate: (0.001, 0.001)\n",
      "Epoch: 103/300, train loss:  42.5368          test_loss:  50.5782, duration: 0:00:37.523396,           learning rate: (0.001, 0.001)\n",
      "Epoch: 104/300, train loss:  42.8839          test_loss:  50.8116, duration: 0:00:37.049549,           learning rate: (0.001, 0.001)\n",
      "Epoch: 105/300, train loss:  42.7941          test_loss:  56.6625, duration: 0:00:37.131639,           learning rate: (0.001, 0.0001)\n",
      "Epoch: 106/300, train loss:  33.9707          test_loss:  44.5824, duration: 0:00:36.802259,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 107/300, train loss:  32.4965          test_loss:  44.3206, duration: 0:00:36.957656,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 108/300, train loss:  31.9385          test_loss:  44.1608, duration: 0:00:36.868772,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 109/300, train loss:  31.6427          test_loss:  43.9191, duration: 0:00:37.283804,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 110/300, train loss:  31.3985          test_loss:  44.0413, duration: 0:00:36.886603,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 111/300, train loss:  31.1632          test_loss:  43.7792, duration: 0:00:37.207163,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 112/300, train loss:  30.9964          test_loss:  43.4084, duration: 0:00:37.368759,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 113/300, train loss:  30.8282          test_loss:  44.3292, duration: 0:00:37.204277,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 114/300, train loss:  30.6992          test_loss:  43.7443, duration: 0:00:37.252434,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 115/300, train loss:  30.5256          test_loss:  43.9472, duration: 0:00:37.229025,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 116/300, train loss:  30.4296          test_loss:  43.6436, duration: 0:00:37.037751,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 117/300, train loss:  30.2811          test_loss:  43.4239, duration: 0:00:36.988118,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 118/300, train loss:  30.1875          test_loss:  43.3947, duration: 0:00:37.045856,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 119/300, train loss:  30.0657          test_loss:  43.5470, duration: 0:00:37.309859,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 120/300, train loss:  29.9802          test_loss:  43.2370, duration: 0:00:37.027930,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 121/300, train loss:  29.8444          test_loss:  43.3213, duration: 0:00:37.065403,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 122/300, train loss:  29.7681          test_loss:  43.2022, duration: 0:00:36.991217,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 123/300, train loss:  29.6974          test_loss:  43.4316, duration: 0:00:37.087281,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 124/300, train loss:  29.5847          test_loss:  43.6293, duration: 0:00:37.249957,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 125/300, train loss:  29.5109          test_loss:  43.1255, duration: 0:00:37.495226,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 126/300, train loss:  29.4007          test_loss:  43.4844, duration: 0:00:37.477416,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 127/300, train loss:  29.3345          test_loss:  42.9843, duration: 0:00:37.258262,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 128/300, train loss:  29.2822          test_loss:  43.3702, duration: 0:00:37.306388,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 129/300, train loss:  29.1985          test_loss:  43.1967, duration: 0:00:37.047290,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 130/300, train loss:  29.1276          test_loss:  42.8558, duration: 0:00:37.325899,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 131/300, train loss:  29.0451          test_loss:  42.9831, duration: 0:00:37.300413,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 132/300, train loss:  28.9599          test_loss:  43.5886, duration: 0:00:37.483413,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 133/300, train loss:  28.9199          test_loss:  43.2685, duration: 0:00:37.483365,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 134/300, train loss:  28.8758          test_loss:  42.8914, duration: 0:00:37.302379,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 135/300, train loss:  28.7848          test_loss:  42.9528, duration: 0:00:37.571096,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 136/300, train loss:  28.7174          test_loss:  43.6870, duration: 0:00:37.411579,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 137/300, train loss:  28.6756          test_loss:  43.3965, duration: 0:00:37.314032,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 138/300, train loss:  28.6035          test_loss:  42.7170, duration: 0:00:37.505064,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 139/300, train loss:  28.5354          test_loss:  42.6122, duration: 0:00:37.184488,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 140/300, train loss:  28.4763          test_loss:  43.1205, duration: 0:00:37.592689,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 141/300, train loss:  28.3934          test_loss:  42.4815, duration: 0:00:37.389282,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 142/300, train loss:  28.3575          test_loss:  42.6268, duration: 0:00:37.312511,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 143/300, train loss:  28.3149          test_loss:  42.3813, duration: 0:00:37.318061,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 144/300, train loss:  28.2385          test_loss:  42.6691, duration: 0:00:37.179549,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 145/300, train loss:  28.2057          test_loss:  42.2842, duration: 0:00:37.399859,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 146/300, train loss:  28.1302          test_loss:  42.5815, duration: 0:00:37.167422,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 147/300, train loss:  28.0839          test_loss:  42.9551, duration: 0:00:37.267448,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 148/300, train loss:  28.0468          test_loss:  42.5053, duration: 0:00:37.217254,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 149/300, train loss:  27.9955          test_loss:  42.9651, duration: 0:00:37.415684,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 150/300, train loss:  27.9057          test_loss:  42.5666, duration: 0:00:37.989900,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 151/300, train loss:  27.8718          test_loss:  42.4340, duration: 0:00:38.247208,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 152/300, train loss:  27.8132          test_loss:  42.5047, duration: 0:00:38.023663,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 153/300, train loss:  27.7441          test_loss:  42.1089, duration: 0:00:37.510785,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 154/300, train loss:  27.7264          test_loss:  42.2964, duration: 0:00:37.309268,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 155/300, train loss:  27.6735          test_loss:  42.4922, duration: 0:00:37.645784,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 156/300, train loss:  27.6039          test_loss:  42.0878, duration: 0:00:37.428069,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 157/300, train loss:  27.5584          test_loss:  42.2410, duration: 0:00:37.222063,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 158/300, train loss:  27.5140          test_loss:  42.2509, duration: 0:00:37.548952,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 159/300, train loss:  27.4436          test_loss:  42.4096, duration: 0:00:37.298639,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 160/300, train loss:  27.3851          test_loss:  42.4881, duration: 0:00:37.319658,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 161/300, train loss:  27.3780          test_loss:  42.3266, duration: 0:00:37.524803,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 162/300, train loss:  27.3209          test_loss:  41.9025, duration: 0:00:37.408283,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 163/300, train loss:  27.2526          test_loss:  41.8677, duration: 0:00:37.397092,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 164/300, train loss:  27.2069          test_loss:  42.0068, duration: 0:00:37.462622,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 165/300, train loss:  27.1688          test_loss:  41.7349, duration: 0:00:37.394660,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 166/300, train loss:  27.0947          test_loss:  42.4020, duration: 0:00:37.443727,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 167/300, train loss:  27.0526          test_loss:  41.8069, duration: 0:00:37.543757,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 168/300, train loss:  27.0231          test_loss:  42.4473, duration: 0:00:37.672718,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 169/300, train loss:  26.9744          test_loss:  41.8165, duration: 0:00:37.855929,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 170/300, train loss:  26.9204          test_loss:  41.7268, duration: 0:00:37.950835,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 171/300, train loss:  26.8594          test_loss:  41.7383, duration: 0:00:37.919598,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 172/300, train loss:  26.8056          test_loss:  41.9917, duration: 0:00:37.721787,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 173/300, train loss:  26.7462          test_loss:  41.7932, duration: 0:00:37.465552,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 174/300, train loss:  26.6975          test_loss:  42.1114, duration: 0:00:37.651977,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 175/300, train loss:  26.6175          test_loss:  41.6261, duration: 0:00:37.618421,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 176/300, train loss:  26.6155          test_loss:  41.6276, duration: 0:00:37.220267,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 177/300, train loss:  26.5033          test_loss:  41.6225, duration: 0:00:37.358863,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 178/300, train loss:  26.4639          test_loss:  42.0746, duration: 0:00:37.588615,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 179/300, train loss:  26.4492          test_loss:  41.4410, duration: 0:00:37.817571,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 180/300, train loss:  26.3537          test_loss:  42.1358, duration: 0:00:38.439656,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 181/300, train loss:  26.3230          test_loss:  41.0149, duration: 0:00:37.877968,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 182/300, train loss:  26.2394          test_loss:  42.6737, duration: 0:00:37.828714,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 183/300, train loss:  26.1868          test_loss:  41.0625, duration: 0:00:37.987929,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 184/300, train loss:  26.1501          test_loss:  41.0037, duration: 0:00:37.973903,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 185/300, train loss:  26.1022          test_loss:  40.7920, duration: 0:00:38.469896,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 186/300, train loss:  26.0331          test_loss:  41.4538, duration: 0:00:38.146205,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 187/300, train loss:  26.0083          test_loss:  41.1520, duration: 0:00:38.051055,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 188/300, train loss:  25.9567          test_loss:  41.3041, duration: 0:00:38.231153,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 189/300, train loss:  25.8874          test_loss:  41.2503, duration: 0:00:37.989259,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 190/300, train loss:  25.8793          test_loss:  40.4046, duration: 0:00:37.943841,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 191/300, train loss:  25.8082          test_loss:  40.7817, duration: 0:00:37.658009,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 192/300, train loss:  25.7203          test_loss:  40.7677, duration: 0:00:37.695220,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 193/300, train loss:  25.7061          test_loss:  40.7268, duration: 0:00:37.146980,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 194/300, train loss:  25.6109          test_loss:  40.7654, duration: 0:00:37.117945,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 195/300, train loss:  25.5964          test_loss:  40.2804, duration: 0:00:37.357942,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 196/300, train loss:  25.5380          test_loss:  40.9190, duration: 0:00:37.356542,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 197/300, train loss:  25.4894          test_loss:  40.4946, duration: 0:00:37.575832,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 198/300, train loss:  25.4239          test_loss:  40.3341, duration: 0:00:37.578887,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 199/300, train loss:  25.3862          test_loss:  40.5854, duration: 0:00:37.176662,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 200/300, train loss:  25.3687          test_loss:  40.0132, duration: 0:00:37.399765,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 201/300, train loss:  25.3079          test_loss:  40.0493, duration: 0:00:37.192127,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 202/300, train loss:  25.2491          test_loss:  39.9581, duration: 0:00:37.125763,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 203/300, train loss:  25.1826          test_loss:  40.3088, duration: 0:00:37.223198,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 204/300, train loss:  25.1291          test_loss:  40.0089, duration: 0:00:37.292443,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 205/300, train loss:  25.0888          test_loss:  39.8308, duration: 0:00:37.426023,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 206/300, train loss:  25.0338          test_loss:  39.6500, duration: 0:00:37.156808,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 207/300, train loss:  24.9880          test_loss:  40.0574, duration: 0:00:37.301783,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 208/300, train loss:  24.9492          test_loss:  39.9964, duration: 0:00:37.246424,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 209/300, train loss:  24.8839          test_loss:  39.9220, duration: 0:00:37.041496,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 210/300, train loss:  24.8590          test_loss:  39.3645, duration: 0:00:37.256891,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 211/300, train loss:  24.7904          test_loss:  39.4999, duration: 0:00:37.123931,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 212/300, train loss:  24.7803          test_loss:  39.4751, duration: 0:00:37.036720,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 213/300, train loss:  24.6896          test_loss:  39.1318, duration: 0:00:37.235174,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 214/300, train loss:  24.6654          test_loss:  38.8180, duration: 0:00:37.244160,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 215/300, train loss:  24.5788          test_loss:  38.7746, duration: 0:00:37.012116,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 216/300, train loss:  24.5333          test_loss:  39.2264, duration: 0:00:37.003422,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 217/300, train loss:  24.5187          test_loss:  38.6039, duration: 0:00:37.026270,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 218/300, train loss:  24.4280          test_loss:  38.6657, duration: 0:00:36.922534,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 219/300, train loss:  24.3974          test_loss:  38.4364, duration: 0:00:37.203641,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 220/300, train loss:  24.3555          test_loss:  38.7919, duration: 0:00:37.233847,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 221/300, train loss:  24.2969          test_loss:  38.3859, duration: 0:00:37.840429,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 222/300, train loss:  24.2426          test_loss:  38.8847, duration: 0:00:37.652009,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 223/300, train loss:  24.1607          test_loss:  38.5540, duration: 0:00:37.218194,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 224/300, train loss:  24.0938          test_loss:  38.9310, duration: 0:00:37.041407,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 225/300, train loss:  24.0356          test_loss:  38.3879, duration: 0:00:37.421640,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 226/300, train loss:  23.9681          test_loss:  38.0040, duration: 0:00:37.340531,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 227/300, train loss:  23.9404          test_loss:  38.1943, duration: 0:00:37.125576,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 228/300, train loss:  23.9053          test_loss:  37.6137, duration: 0:00:37.420545,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 229/300, train loss:  23.8052          test_loss:  38.1506, duration: 0:00:37.161224,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 230/300, train loss:  23.7838          test_loss:  37.3494, duration: 0:00:37.395873,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 231/300, train loss:  23.7053          test_loss:  37.5052, duration: 0:00:37.256681,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 232/300, train loss:  23.6539          test_loss:  37.8263, duration: 0:00:37.594960,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 233/300, train loss:  23.5748          test_loss:  38.4124, duration: 0:00:37.337913,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 234/300, train loss:  23.5201          test_loss:  37.3266, duration: 0:00:37.094690,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 235/300, train loss:  23.4350          test_loss:  37.1075, duration: 0:00:37.260053,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 236/300, train loss:  23.3926          test_loss:  37.3188, duration: 0:00:37.207068,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 237/300, train loss:  23.3544          test_loss:  37.4852, duration: 0:00:37.276190,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 238/300, train loss:  23.2672          test_loss:  36.9561, duration: 0:00:37.472954,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 239/300, train loss:  23.2216          test_loss:  36.5558, duration: 0:00:37.161208,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 240/300, train loss:  23.1217          test_loss:  36.6730, duration: 0:00:37.050884,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 241/300, train loss:  23.0876          test_loss:  37.4376, duration: 0:00:37.428754,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 242/300, train loss:  23.0149          test_loss:  36.5534, duration: 0:00:37.411728,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 243/300, train loss:  22.9385          test_loss:  36.3299, duration: 0:00:36.995329,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 244/300, train loss:  22.8762          test_loss:  36.1989, duration: 0:00:37.139546,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 245/300, train loss:  22.8126          test_loss:  35.9456, duration: 0:00:37.179160,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 246/300, train loss:  22.7496          test_loss:  36.5783, duration: 0:00:37.211404,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 247/300, train loss:  22.6590          test_loss:  36.4657, duration: 0:00:37.310910,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 248/300, train loss:  22.5860          test_loss:  36.4350, duration: 0:00:37.356170,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 249/300, train loss:  22.5373          test_loss:  35.5620, duration: 0:00:37.108662,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 250/300, train loss:  22.4373          test_loss:  35.6300, duration: 0:00:37.194578,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 251/300, train loss:  22.3402          test_loss:  35.5755, duration: 0:00:37.408290,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 252/300, train loss:  22.2980          test_loss:  35.6736, duration: 0:00:37.093900,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 253/300, train loss:  22.2145          test_loss:  35.9101, duration: 0:00:37.554617,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 254/300, train loss:  22.0946          test_loss:  35.1799, duration: 0:00:37.713857,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 255/300, train loss:  22.0592          test_loss:  35.3040, duration: 0:00:37.519740,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 256/300, train loss:  21.9721          test_loss:  35.2580, duration: 0:00:37.403933,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 257/300, train loss:  21.9227          test_loss:  34.6173, duration: 0:00:37.333688,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 258/300, train loss:  21.7985          test_loss:  35.2093, duration: 0:00:37.104055,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 259/300, train loss:  21.7527          test_loss:  34.4925, duration: 0:00:37.034326,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 260/300, train loss:  21.6391          test_loss:  34.9112, duration: 0:00:37.149806,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 261/300, train loss:  21.5647          test_loss:  34.0066, duration: 0:00:37.280671,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 262/300, train loss:  21.4749          test_loss:  33.9227, duration: 0:00:37.360015,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 263/300, train loss:  21.3580          test_loss:  33.7554, duration: 0:00:37.267059,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 264/300, train loss:  21.2926          test_loss:  33.3925, duration: 0:00:37.398400,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 265/300, train loss:  21.1969          test_loss:  34.0543, duration: 0:00:37.367594,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 266/300, train loss:  21.0868          test_loss:  35.9950, duration: 0:00:37.147043,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 267/300, train loss:  21.0409          test_loss:  33.3994, duration: 0:00:37.488017,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 268/300, train loss:  20.9075          test_loss:  32.5969, duration: 0:00:37.511860,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 269/300, train loss:  20.7934          test_loss:  33.1416, duration: 0:00:37.512341,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 270/300, train loss:  20.7079          test_loss:  32.4165, duration: 0:00:37.352298,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 271/300, train loss:  20.6232          test_loss:  32.5113, duration: 0:00:37.199829,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 272/300, train loss:  20.5189          test_loss:  32.4847, duration: 0:00:37.078119,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 273/300, train loss:  20.4008          test_loss:  33.0157, duration: 0:00:37.454657,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 274/300, train loss:  20.2928          test_loss:  31.8694, duration: 0:00:37.219729,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 275/300, train loss:  20.1810          test_loss:  32.1326, duration: 0:00:37.410369,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 276/300, train loss:  20.0404          test_loss:  31.7371, duration: 0:00:37.411088,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 277/300, train loss:  19.9939          test_loss:  32.1176, duration: 0:00:37.294824,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 278/300, train loss:  19.8101          test_loss:  32.2994, duration: 0:00:37.149263,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 279/300, train loss:  19.7589          test_loss:  31.3953, duration: 0:00:37.186529,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 280/300, train loss:  19.6638          test_loss:  30.9894, duration: 0:00:37.188015,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 281/300, train loss:  19.5026          test_loss:  30.7439, duration: 0:00:37.060663,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 282/300, train loss:  19.3984          test_loss:  30.8646, duration: 0:00:37.838743,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 283/300, train loss:  19.3351          test_loss:  32.4472, duration: 0:00:37.769964,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 284/300, train loss:  19.1670          test_loss:  30.4563, duration: 0:00:37.524440,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 285/300, train loss:  19.0681          test_loss:  31.4579, duration: 0:00:37.261972,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 286/300, train loss:  18.9808          test_loss:  30.0517, duration: 0:00:37.174408,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 287/300, train loss:  18.8781          test_loss:  29.9205, duration: 0:00:37.467114,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 288/300, train loss:  18.7599          test_loss:  30.8434, duration: 0:00:37.287514,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 289/300, train loss:  18.6241          test_loss:  30.2804, duration: 0:00:37.077995,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 290/300, train loss:  18.5400          test_loss:  29.5105, duration: 0:00:37.062152,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 291/300, train loss:  18.4216          test_loss:  29.5530, duration: 0:00:37.146275,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 292/300, train loss:  18.3465          test_loss:  29.1015, duration: 0:00:37.307156,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 293/300, train loss:  18.2474          test_loss:  32.0414, duration: 0:00:37.341432,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 294/300, train loss:  18.1398          test_loss:  30.5341, duration: 0:00:37.501369,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 295/300, train loss:  18.0345          test_loss:  29.0113, duration: 0:00:37.199952,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 296/300, train loss:  17.9714          test_loss:  28.6904, duration: 0:00:37.526369,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 297/300, train loss:  17.8152          test_loss:  28.1298, duration: 0:00:37.545787,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 298/300, train loss:  17.7135          test_loss:  28.1333, duration: 0:00:37.244523,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 299/300, train loss:  17.6710          test_loss:  28.0018, duration: 0:00:37.256747,           learning rate: (0.0001, 0.0001)\n",
      "Epoch: 300/300, train loss:  17.5470          test_loss:  27.2577, duration: 0:00:37.181907,           learning rate: (0.0001, 0.0001)\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses=batch_gd_scheduler(model, criterion, optimizer, train_gen, test_gen, scheduler, \n",
    "                                             max_epoch, device,  cnn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18337ad4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T09:55:34.881892Z",
     "iopub.status.busy": "2024-03-28T09:55:34.881198Z",
     "iopub.status.idle": "2024-03-28T09:55:34.904241Z",
     "shell.execute_reply": "2024-03-28T09:55:34.903372Z"
    },
    "papermill": {
     "duration": 0.057871,
     "end_time": "2024-03-28T09:55:34.906447",
     "exception": false,
     "start_time": "2024-03-28T09:55:34.848576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>377.622157</td>\n",
       "      <td>199.562614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189.026494</td>\n",
       "      <td>190.944042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173.872692</td>\n",
       "      <td>144.378279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>158.572064</td>\n",
       "      <td>163.734670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146.903493</td>\n",
       "      <td>138.926152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss   test_loss\n",
       "0  377.622157  199.562614\n",
       "1  189.026494  190.944042\n",
       "2  173.872692  144.378279\n",
       "3  158.572064  163.734670\n",
       "4  146.903493  138.926152"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "loss_dict = {'train_loss': train_losses, 'test_loss': test_losses}\n",
    "dd = pd.DataFrame(loss_dict)\n",
    "dd.to_csv('loss_dict.csv', index = False)\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2c14c62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T09:55:34.971918Z",
     "iopub.status.busy": "2024-03-28T09:55:34.971282Z",
     "iopub.status.idle": "2024-03-28T09:55:35.260287Z",
     "shell.execute_reply": "2024-03-28T09:55:35.259349Z"
    },
    "papermill": {
     "duration": 0.323556,
     "end_time": "2024-03-28T09:55:35.262373",
     "exception": false,
     "start_time": "2024-03-28T09:55:34.938817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc84a491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T09:55:35.331039Z",
     "iopub.status.busy": "2024-03-28T09:55:35.330415Z",
     "iopub.status.idle": "2024-03-28T09:55:52.245598Z",
     "shell.execute_reply": "2024-03-28T09:55:52.244702Z"
    },
    "papermill": {
     "duration": 16.951388,
     "end_time": "2024-03-28T09:55:52.247884",
     "exception": false,
     "start_time": "2024-03-28T09:55:35.296496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for h11:0.4721, Test accuracy for h11: 0.4715\n",
      "Train accuracy for h21:0.6062, Test accuracy for h21: 0.6039\n",
      "Train accuracy for h31:0.2472, Test accuracy for h31: 0.2337\n",
      "Train accuracy for h22:0.0889, Test accuracy for h22: 0.0848\n"
     ]
    }
   ],
   "source": [
    "train_acc, test_acc = calc_accuracy_mr(model, train_gen , test_gen, device = device, cnn= False)\n",
    "print(f'Train accuracy for h11:{train_acc[0]:.4f}, Test accuracy for h11: {test_acc[0]:.4f}')\n",
    "print(f'Train accuracy for h21:{train_acc[1]:.4f}, Test accuracy for h21: {test_acc[1]:.4f}')\n",
    "print(f'Train accuracy for h31:{train_acc[2]:.4f}, Test accuracy for h31: {test_acc[2]:.4f}')\n",
    "print(f'Train accuracy for h22:{train_acc[3]:.4f}, Test accuracy for h22: {test_acc[3]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "899d8a68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T09:55:52.314855Z",
     "iopub.status.busy": "2024-03-28T09:55:52.314100Z",
     "iopub.status.idle": "2024-03-28T09:55:52.333407Z",
     "shell.execute_reply": "2024-03-28T09:55:52.332511Z"
    },
    "papermill": {
     "duration": 0.054308,
     "end_time": "2024-03-28T09:55:52.335296",
     "exception": false,
     "start_time": "2024-03-28T09:55:52.280988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, '/kaggle/working/saved_models/CNN_GRU_hybrid_cicy4_Hodge_v7.pt')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4575883,
     "sourceId": 7953742,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11242.810907,
   "end_time": "2024-03-28T09:55:54.116044",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-28T06:48:31.305137",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
